{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"57xWvIp3Y3jk","executionInfo":{"status":"ok","timestamp":1716181656008,"user_tz":420,"elapsed":9139,"user":{"displayName":"Samara Miramontes","userId":"13244449749203433893"}}},"outputs":[],"source":["########################################################################\n","# 2. DEFINE YOUR CONVOLUTIONAL NEURAL NETWORK\n","########################################################################\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","class ConvNet(nn.Module):\n","    def __init__(self, init_weights=False):\n","        super(ConvNet, self).__init__()\n","        # Initialize layers here\n","        self.layer1 = nn.Sequential(\n","            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(32),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Dropout(0.25)\n","        )\n","        self.layer2 = nn.Sequential(\n","            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Dropout(0.25)\n","        )\n","        self.layer3 = nn.Sequential(\n","            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Dropout(0.25)\n","        )\n","        self.layer4 = nn.Sequential(\n","            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Dropout(0.25)\n","        )\n","        self.fc1 = nn.Linear(2 * 2 * 256, 512)\n","        self.fc2 = nn.Linear(512, 10)\n","\n","        if init_weights:\n","            self._initialize_weights()\n","\n","    def forward(self, x):\n","        # Pass image x through each layer defined above\n","        out = self.layer1(x)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = self.layer4(out)\n","        out = out.view(out.size(0), -1)\n","        out = self.fc1(out)\n","        out = self.fc2(out)\n","        return out\n","\n","    def _initialize_weights(self):\n","        # Initialize weights\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","            elif isinstance(m, nn.BatchNorm2d):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)\n","            elif isinstance(m, nn.Linear):\n","                nn.init.normal_(m.weight, 0, 0.01)\n","                nn.init.constant_(m.bias, 0)\n"]},{"cell_type":"code","source":["\"\"\"\n","---------------------------------------------------------------------\n","Training an image classifier\n","---------------------------------------------------------------------\n","For this assingment you'll do the following steps in order:\n","1. Load and normalizing the CIFAR10 training and test datasets using\n","   ``torchvision``\n","2. Define a Convolutional Neural Network (at least 4 conv layer)\n","3. Define a loss function\n","4. Train the network on the training data\n","5. Test the network on the test data\n","---------------------------------------------------------------------\n","\"\"\"\n","\n","# IMPORTING REQUIRED PACKAGES\n","import os\n","import numpy as np\n","import scipy.io as sio\n","import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.nn as nn\n","import torch.optim as optim\n","#from cnn_model import ConvNet\n","\n","# DEFINE VARIABLE\n","BATCH_SIZE = 32                 # YOU MAY CHANGE THIS VALUE\n","EPOCH_NUM = 25                  # YOU MAY CHANGE THIS VALUE\n","LR = 0.001                      # YOU MAY CHANGE THIS VALUE\n","MODEL_SAVE_PATH = './Models'\n","\n","if not os.path.exists(MODEL_SAVE_PATH):\n","    os.mkdir(MODEL_SAVE_PATH)\n","\n","# DEFINING TRANSFORM TO APPLY TO THE IMAGES\n","# YOU MAY ADD OTHER TRANSFORMS FOR DATA AUGMENTATION\n","transform = transforms.Compose(\n","    [transforms.Resize(32),\n","     transforms.ToTensor(),\n","     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","\n","########################################################################\n","# 1. LOAD AND NORMALIZE CIFAR10 DATASET\n","########################################################################\n","\n","# Get train and test dataset from torchvision and create respective dataloader\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n","\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n","\n","########################################################################\n","# 2. DEFINE YOUR CONVOLUTIONAL NEURAL NETWORK AND IMPORT IT\n","########################################################################\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","net = ConvNet().to(device) # MAKE SURE TO DEFINE ConvNet IN A CELL ABOVE THE STARTER CODE OF WHICH IS IN cnn_model.py\n","# You can pass arguments to ConvNet if you want instead of hard coding them.\n","\n","########################################################################\n","# 3. DEFINE A LOSS FUNCTION AND OPTIMIZER\n","########################################################################\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(net.parameters(), lr=LR, momentum=0.9)\n","\n","########################################################################\n","# 4. TRAIN THE NETWORK\n","########################################################################\n","\n","test_accuracy = []\n","train_accuracy = []\n","train_loss = []\n","net.train()\n","\n","for epoch in range(EPOCH_NUM):  # loop over the dataset multiple times\n","\n","    running_loss = 0.0\n","    test_min_acc = 0\n","    total = 0\n","    correct = 0\n","\n","    for i, data in enumerate(trainloader, 0):\n","        # get the inputs\n","        inputs, labels = data\n","\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # forward + backward + optimize\n","        outputs = net(inputs.to(device))\n","        loss = criterion(outputs, labels.to(device))\n","        loss.backward()\n","        optimizer.step()\n","\n","        # print statistics\n","        running_loss += loss.item()\n","        _, predicted = torch.max(outputs.data, 1)\n","\n","        # Obtain accuracy for the given batch of TRAINING data\n","        total += labels.size(0)\n","        correct += (predicted == labels.to(device)).sum().item()\n","\n","        if i % 20 == 19:    # print every 20 mini-batches\n","            print('Train: [%d, %5d] loss: %.3f acc: %.3f' %\n","                  (epoch + 1, i + 1, running_loss / 20, 100.0 * correct / total))\n","            running_loss = 0.0\n","\n","    train_loss.append(running_loss / len(trainloader))\n","    train_accuracy.append(100.0 * correct / total)\n","\n","    # TEST LEARNT MODEL ON ENTIRE TESTSET\n","    correct = 0\n","    total = 0\n","    net.eval()\n","    with torch.no_grad():\n","        for data in testloader:\n","            images, labels = data\n","            outputs = net(images.to(device))\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels.to(device)).sum().item()\n","\n","    test_acc = 100.0 * correct / total\n","    test_accuracy.append(test_acc)\n","    print('Test Accuracy: %.3f %%' % test_acc)\n","\n","    # SAVE BEST MODEL\n","    if test_min_acc < test_acc:\n","        test_min_acc = test_acc\n","        torch.save(net, MODEL_SAVE_PATH + '/my_best_model.pth')\n","\n","# PLOT THE TRAINING LOSS VS EPOCH GRAPH\n","# PLOT THE TESTING ACCURACY VS EPOCH GRAPH\n","# PRINT THE FINAL TESTING ACCURACY OF YOUR BEST MODEL\n","\n","import matplotlib.pyplot as plt\n","\n","plt.figure()\n","plt.plot(range(EPOCH_NUM), train_loss, label='Training Loss')\n","plt.plot(range(EPOCH_NUM), train_accuracy, label='Training Accuracy')\n","plt.plot(range(EPOCH_NUM), test_accuracy, label='Test Accuracy')\n","plt.legend()\n","plt.xlabel('Epoch')\n","plt.ylabel('Value')\n","plt.title('Training Loss and Accuracy')\n","plt.show()\n","\n","print('Finished Training')\n","print('Final Test Accuracy of the Best Model: %.3f %%' % test_min_acc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"0doEwEWAZZSf","executionInfo":{"status":"ok","timestamp":1716187026225,"user_tz":420,"elapsed":5104409,"user":{"displayName":"Samara Miramontes","userId":"13244449749203433893"}},"outputId":"9365dfa8-0629-427d-f778-5299ba9945bb"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 170498071/170498071 [00:02<00:00, 79310721.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/cifar-10-python.tar.gz to ./data\n","Files already downloaded and verified\n"]},{"output_type":"stream","name":"stderr","text":["/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]},{"output_type":"stream","name":"stdout","text":["Train: [1,    20] loss: 2.346 acc: 10.625\n","Train: [1,    40] loss: 2.226 acc: 14.062\n","Train: [1,    60] loss: 2.088 acc: 17.083\n","Train: [1,    80] loss: 2.014 acc: 18.945\n","Train: [1,   100] loss: 1.947 acc: 20.500\n","Train: [1,   120] loss: 1.972 acc: 21.016\n","Train: [1,   140] loss: 1.838 acc: 23.013\n","Train: [1,   160] loss: 1.875 acc: 24.141\n","Train: [1,   180] loss: 1.807 acc: 25.330\n","Train: [1,   200] loss: 1.784 acc: 25.891\n","Train: [1,   220] loss: 1.789 acc: 26.534\n","Train: [1,   240] loss: 1.724 acc: 27.135\n","Train: [1,   260] loss: 1.712 acc: 27.837\n","Train: [1,   280] loss: 1.683 acc: 28.549\n","Train: [1,   300] loss: 1.695 acc: 29.115\n","Train: [1,   320] loss: 1.609 acc: 29.824\n","Train: [1,   340] loss: 1.607 acc: 30.414\n","Train: [1,   360] loss: 1.632 acc: 30.833\n","Train: [1,   380] loss: 1.656 acc: 31.234\n","Train: [1,   400] loss: 1.671 acc: 31.688\n","Train: [1,   420] loss: 1.687 acc: 32.054\n","Train: [1,   440] loss: 1.553 acc: 32.521\n","Train: [1,   460] loss: 1.556 acc: 32.846\n","Train: [1,   480] loss: 1.608 acc: 33.255\n","Train: [1,   500] loss: 1.566 acc: 33.556\n","Train: [1,   520] loss: 1.577 acc: 33.912\n","Train: [1,   540] loss: 1.544 acc: 34.225\n","Train: [1,   560] loss: 1.543 acc: 34.548\n","Train: [1,   580] loss: 1.547 acc: 34.876\n","Train: [1,   600] loss: 1.591 acc: 35.146\n","Train: [1,   620] loss: 1.585 acc: 35.418\n","Train: [1,   640] loss: 1.526 acc: 35.654\n","Train: [1,   660] loss: 1.571 acc: 35.914\n","Train: [1,   680] loss: 1.553 acc: 36.186\n","Train: [1,   700] loss: 1.497 acc: 36.406\n","Train: [1,   720] loss: 1.474 acc: 36.628\n","Train: [1,   740] loss: 1.586 acc: 36.736\n","Train: [1,   760] loss: 1.464 acc: 37.048\n","Train: [1,   780] loss: 1.518 acc: 37.167\n","Train: [1,   800] loss: 1.506 acc: 37.391\n","Train: [1,   820] loss: 1.507 acc: 37.576\n","Train: [1,   840] loss: 1.516 acc: 37.723\n","Train: [1,   860] loss: 1.524 acc: 37.911\n","Train: [1,   880] loss: 1.452 acc: 38.086\n","Train: [1,   900] loss: 1.510 acc: 38.260\n","Train: [1,   920] loss: 1.489 acc: 38.451\n","Train: [1,   940] loss: 1.421 acc: 38.627\n","Train: [1,   960] loss: 1.470 acc: 38.750\n","Train: [1,   980] loss: 1.548 acc: 38.827\n","Train: [1,  1000] loss: 1.375 acc: 39.091\n","Train: [1,  1020] loss: 1.425 acc: 39.262\n","Train: [1,  1040] loss: 1.501 acc: 39.372\n","Train: [1,  1060] loss: 1.343 acc: 39.570\n","Train: [1,  1080] loss: 1.505 acc: 39.653\n","Train: [1,  1100] loss: 1.442 acc: 39.832\n","Train: [1,  1120] loss: 1.412 acc: 39.983\n","Train: [1,  1140] loss: 1.438 acc: 40.096\n","Train: [1,  1160] loss: 1.453 acc: 40.202\n","Train: [1,  1180] loss: 1.396 acc: 40.318\n","Train: [1,  1200] loss: 1.377 acc: 40.477\n","Train: [1,  1220] loss: 1.483 acc: 40.548\n","Train: [1,  1240] loss: 1.412 acc: 40.650\n","Train: [1,  1260] loss: 1.429 acc: 40.779\n","Train: [1,  1280] loss: 1.382 acc: 40.935\n","Train: [1,  1300] loss: 1.337 acc: 41.079\n","Train: [1,  1320] loss: 1.354 acc: 41.222\n","Train: [1,  1340] loss: 1.394 acc: 41.348\n","Train: [1,  1360] loss: 1.393 acc: 41.427\n","Train: [1,  1380] loss: 1.360 acc: 41.531\n","Train: [1,  1400] loss: 1.380 acc: 41.638\n","Train: [1,  1420] loss: 1.334 acc: 41.767\n","Train: [1,  1440] loss: 1.344 acc: 41.899\n","Train: [1,  1460] loss: 1.411 acc: 41.993\n","Train: [1,  1480] loss: 1.209 acc: 42.181\n","Train: [1,  1500] loss: 1.330 acc: 42.346\n","Train: [1,  1520] loss: 1.357 acc: 42.475\n","Train: [1,  1540] loss: 1.288 acc: 42.597\n","Train: [1,  1560] loss: 1.437 acc: 42.696\n","Test Accuracy: 44.660 %\n","Train: [2,    20] loss: 1.326 acc: 53.750\n","Train: [2,    40] loss: 1.207 acc: 54.922\n","Train: [2,    60] loss: 1.216 acc: 54.844\n","Train: [2,    80] loss: 1.211 acc: 55.078\n","Train: [2,   100] loss: 1.249 acc: 55.094\n","Train: [2,   120] loss: 1.267 acc: 54.948\n","Train: [2,   140] loss: 1.162 acc: 55.089\n","Train: [2,   160] loss: 1.184 acc: 55.430\n","Train: [2,   180] loss: 1.201 acc: 55.799\n","Train: [2,   200] loss: 1.070 acc: 56.453\n","Train: [2,   220] loss: 1.240 acc: 56.548\n","Train: [2,   240] loss: 1.241 acc: 56.549\n","Train: [2,   260] loss: 1.213 acc: 56.550\n","Train: [2,   280] loss: 1.052 acc: 57.031\n","Train: [2,   300] loss: 1.205 acc: 57.031\n","Train: [2,   320] loss: 1.167 acc: 56.963\n","Train: [2,   340] loss: 1.215 acc: 57.004\n","Train: [2,   360] loss: 1.208 acc: 57.083\n","Train: [2,   380] loss: 1.100 acc: 57.311\n","Train: [2,   400] loss: 1.117 acc: 57.422\n","Train: [2,   420] loss: 1.101 acc: 57.589\n","Train: [2,   440] loss: 1.179 acc: 57.607\n","Train: [2,   460] loss: 1.145 acc: 57.697\n","Train: [2,   480] loss: 1.106 acc: 57.910\n","Train: [2,   500] loss: 1.095 acc: 58.100\n","Train: [2,   520] loss: 1.155 acc: 58.185\n","Train: [2,   540] loss: 1.063 acc: 58.287\n","Train: [2,   560] loss: 1.034 acc: 58.532\n","Train: [2,   580] loss: 1.147 acc: 58.556\n","Train: [2,   600] loss: 1.150 acc: 58.552\n","Train: [2,   620] loss: 1.097 acc: 58.543\n","Train: [2,   640] loss: 1.114 acc: 58.584\n","Train: [2,   660] loss: 1.109 acc: 58.622\n","Train: [2,   680] loss: 1.109 acc: 58.640\n","Train: [2,   700] loss: 1.062 acc: 58.723\n","Train: [2,   720] loss: 1.061 acc: 58.811\n","Train: [2,   740] loss: 1.037 acc: 58.919\n","Train: [2,   760] loss: 1.060 acc: 59.030\n","Train: [2,   780] loss: 1.036 acc: 59.147\n","Train: [2,   800] loss: 1.080 acc: 59.207\n","Train: [2,   820] loss: 1.036 acc: 59.314\n","Train: [2,   840] loss: 0.976 acc: 59.449\n","Train: [2,   860] loss: 1.061 acc: 59.535\n","Train: [2,   880] loss: 1.050 acc: 59.631\n","Train: [2,   900] loss: 1.133 acc: 59.635\n","Train: [2,   920] loss: 1.107 acc: 59.667\n","Train: [2,   940] loss: 1.019 acc: 59.774\n","Train: [2,   960] loss: 0.979 acc: 59.854\n","Train: [2,   980] loss: 1.010 acc: 59.882\n","Train: [2,  1000] loss: 1.012 acc: 59.956\n","Train: [2,  1020] loss: 0.995 acc: 60.070\n","Train: [2,  1040] loss: 0.965 acc: 60.213\n","Train: [2,  1060] loss: 0.964 acc: 60.330\n","Train: [2,  1080] loss: 1.016 acc: 60.388\n","Train: [2,  1100] loss: 0.950 acc: 60.489\n","Train: [2,  1120] loss: 0.969 acc: 60.617\n","Train: [2,  1140] loss: 0.989 acc: 60.650\n","Train: [2,  1160] loss: 1.045 acc: 60.682\n","Train: [2,  1180] loss: 1.031 acc: 60.736\n","Train: [2,  1200] loss: 1.039 acc: 60.760\n","Train: [2,  1220] loss: 1.039 acc: 60.768\n","Train: [2,  1240] loss: 0.996 acc: 60.814\n","Train: [2,  1260] loss: 0.977 acc: 60.873\n","Train: [2,  1280] loss: 1.026 acc: 60.884\n","Train: [2,  1300] loss: 0.947 acc: 60.971\n","Train: [2,  1320] loss: 0.941 acc: 61.063\n","Train: [2,  1340] loss: 0.963 acc: 61.129\n","Train: [2,  1360] loss: 0.989 acc: 61.158\n","Train: [2,  1380] loss: 1.034 acc: 61.182\n","Train: [2,  1400] loss: 1.016 acc: 61.205\n","Train: [2,  1420] loss: 0.992 acc: 61.246\n","Train: [2,  1440] loss: 0.999 acc: 61.317\n","Train: [2,  1460] loss: 0.982 acc: 61.361\n","Train: [2,  1480] loss: 1.018 acc: 61.383\n","Train: [2,  1500] loss: 1.011 acc: 61.410\n","Train: [2,  1520] loss: 0.922 acc: 61.470\n","Train: [2,  1540] loss: 0.962 acc: 61.528\n","Train: [2,  1560] loss: 0.936 acc: 61.591\n","Test Accuracy: 62.360 %\n","Train: [3,    20] loss: 1.003 acc: 64.219\n","Train: [3,    40] loss: 0.909 acc: 65.859\n","Train: [3,    60] loss: 0.882 acc: 66.562\n","Train: [3,    80] loss: 0.885 acc: 67.227\n","Train: [3,   100] loss: 0.913 acc: 67.312\n","Train: [3,   120] loss: 0.846 acc: 67.500\n","Train: [3,   140] loss: 0.978 acc: 67.455\n","Train: [3,   160] loss: 0.914 acc: 67.539\n","Train: [3,   180] loss: 0.878 acc: 67.951\n","Train: [3,   200] loss: 0.911 acc: 68.016\n","Train: [3,   220] loss: 0.887 acc: 68.082\n","Train: [3,   240] loss: 0.888 acc: 68.047\n","Train: [3,   260] loss: 0.959 acc: 67.945\n","Train: [3,   280] loss: 0.935 acc: 67.790\n","Train: [3,   300] loss: 0.864 acc: 67.927\n","Train: [3,   320] loss: 0.814 acc: 67.959\n","Train: [3,   340] loss: 0.915 acc: 67.987\n","Train: [3,   360] loss: 0.903 acc: 67.873\n","Train: [3,   380] loss: 0.870 acc: 67.837\n","Train: [3,   400] loss: 0.953 acc: 67.867\n","Train: [3,   420] loss: 0.825 acc: 68.006\n","Train: [3,   440] loss: 0.952 acc: 67.983\n","Train: [3,   460] loss: 0.887 acc: 68.043\n","Train: [3,   480] loss: 0.815 acc: 68.171\n","Train: [3,   500] loss: 0.921 acc: 68.181\n","Train: [3,   520] loss: 0.868 acc: 68.245\n","Train: [3,   540] loss: 0.868 acc: 68.252\n","Train: [3,   560] loss: 0.889 acc: 68.298\n","Train: [3,   580] loss: 0.952 acc: 68.233\n","Train: [3,   600] loss: 0.846 acc: 68.344\n","Train: [3,   620] loss: 0.793 acc: 68.463\n","Train: [3,   640] loss: 0.831 acc: 68.599\n","Train: [3,   660] loss: 0.884 acc: 68.589\n","Train: [3,   680] loss: 0.820 acc: 68.585\n","Train: [3,   700] loss: 0.847 acc: 68.634\n","Train: [3,   720] loss: 0.795 acc: 68.724\n","Train: [3,   740] loss: 0.896 acc: 68.708\n","Train: [3,   760] loss: 0.937 acc: 68.647\n","Train: [3,   780] loss: 0.896 acc: 68.634\n","Train: [3,   800] loss: 0.830 acc: 68.656\n","Train: [3,   820] loss: 0.878 acc: 68.609\n","Train: [3,   840] loss: 0.904 acc: 68.616\n","Train: [3,   860] loss: 0.850 acc: 68.692\n","Train: [3,   880] loss: 0.854 acc: 68.700\n","Train: [3,   900] loss: 0.868 acc: 68.722\n","Train: [3,   920] loss: 0.834 acc: 68.767\n","Train: [3,   940] loss: 0.792 acc: 68.870\n","Train: [3,   960] loss: 0.853 acc: 68.883\n","Train: [3,   980] loss: 0.800 acc: 68.916\n","Train: [3,  1000] loss: 0.838 acc: 68.909\n","Train: [3,  1020] loss: 0.856 acc: 68.915\n","Train: [3,  1040] loss: 0.794 acc: 68.951\n","Train: [3,  1060] loss: 0.862 acc: 68.953\n","Train: [3,  1080] loss: 0.835 acc: 68.979\n","Train: [3,  1100] loss: 0.795 acc: 69.065\n","Train: [3,  1120] loss: 0.824 acc: 69.088\n","Train: [3,  1140] loss: 0.897 acc: 69.079\n","Train: [3,  1160] loss: 0.843 acc: 69.076\n","Train: [3,  1180] loss: 0.819 acc: 69.118\n","Train: [3,  1200] loss: 0.892 acc: 69.099\n","Train: [3,  1220] loss: 0.731 acc: 69.147\n","Train: [3,  1240] loss: 0.775 acc: 69.221\n","Train: [3,  1260] loss: 0.868 acc: 69.244\n","Train: [3,  1280] loss: 0.774 acc: 69.304\n","Train: [3,  1300] loss: 0.891 acc: 69.308\n","Train: [3,  1320] loss: 0.783 acc: 69.342\n","Train: [3,  1340] loss: 0.770 acc: 69.419\n","Train: [3,  1360] loss: 0.781 acc: 69.474\n","Train: [3,  1380] loss: 0.846 acc: 69.493\n","Train: [3,  1400] loss: 0.769 acc: 69.536\n","Train: [3,  1420] loss: 0.827 acc: 69.547\n","Train: [3,  1440] loss: 0.774 acc: 69.601\n","Train: [3,  1460] loss: 0.778 acc: 69.636\n","Train: [3,  1480] loss: 0.785 acc: 69.673\n","Train: [3,  1500] loss: 0.902 acc: 69.652\n","Train: [3,  1520] loss: 0.887 acc: 69.659\n","Train: [3,  1540] loss: 0.773 acc: 69.696\n","Train: [3,  1560] loss: 0.829 acc: 69.718\n","Test Accuracy: 67.790 %\n","Train: [4,    20] loss: 0.824 acc: 70.312\n","Train: [4,    40] loss: 0.689 acc: 72.734\n","Train: [4,    60] loss: 0.707 acc: 73.229\n","Train: [4,    80] loss: 0.751 acc: 73.242\n","Train: [4,   100] loss: 0.822 acc: 73.000\n","Train: [4,   120] loss: 0.788 acc: 72.396\n","Train: [4,   140] loss: 0.746 acc: 72.545\n","Train: [4,   160] loss: 0.669 acc: 72.930\n","Train: [4,   180] loss: 0.678 acc: 73.385\n","Train: [4,   200] loss: 0.776 acc: 73.078\n","Train: [4,   220] loss: 0.790 acc: 73.040\n","Train: [4,   240] loss: 0.755 acc: 73.021\n","Train: [4,   260] loss: 0.752 acc: 73.017\n","Train: [4,   280] loss: 0.769 acc: 72.958\n","Train: [4,   300] loss: 0.861 acc: 72.656\n","Train: [4,   320] loss: 0.731 acc: 72.764\n","Train: [4,   340] loss: 0.656 acc: 72.996\n","Train: [4,   360] loss: 0.702 acc: 73.255\n","Train: [4,   380] loss: 0.779 acc: 73.248\n","Train: [4,   400] loss: 0.691 acc: 73.438\n","Train: [4,   420] loss: 0.693 acc: 73.564\n","Train: [4,   440] loss: 0.680 acc: 73.643\n","Train: [4,   460] loss: 0.742 acc: 73.716\n","Train: [4,   480] loss: 0.731 acc: 73.763\n","Train: [4,   500] loss: 0.717 acc: 73.862\n","Train: [4,   520] loss: 0.613 acc: 74.050\n","Train: [4,   540] loss: 0.770 acc: 73.958\n","Train: [4,   560] loss: 0.633 acc: 74.068\n","Train: [4,   580] loss: 0.781 acc: 73.976\n","Train: [4,   600] loss: 0.740 acc: 74.000\n","Train: [4,   620] loss: 0.712 acc: 74.037\n","Train: [4,   640] loss: 0.681 acc: 74.116\n","Train: [4,   660] loss: 0.655 acc: 74.219\n","Train: [4,   680] loss: 0.812 acc: 74.141\n","Train: [4,   700] loss: 0.734 acc: 74.214\n","Train: [4,   720] loss: 0.765 acc: 74.132\n","Train: [4,   740] loss: 0.678 acc: 74.202\n","Train: [4,   760] loss: 0.668 acc: 74.252\n","Train: [4,   780] loss: 0.716 acc: 74.271\n","Train: [4,   800] loss: 0.741 acc: 74.309\n","Train: [4,   820] loss: 0.781 acc: 74.303\n","Train: [4,   840] loss: 0.706 acc: 74.312\n","Train: [4,   860] loss: 0.705 acc: 74.339\n","Train: [4,   880] loss: 0.812 acc: 74.318\n","Train: [4,   900] loss: 0.663 acc: 74.361\n","Train: [4,   920] loss: 0.794 acc: 74.331\n","Train: [4,   940] loss: 0.738 acc: 74.318\n","Train: [4,   960] loss: 0.712 acc: 74.300\n","Train: [4,   980] loss: 0.703 acc: 74.330\n","Train: [4,  1000] loss: 0.690 acc: 74.362\n","Train: [4,  1020] loss: 0.672 acc: 74.418\n","Train: [4,  1040] loss: 0.685 acc: 74.456\n","Train: [4,  1060] loss: 0.652 acc: 74.519\n","Train: [4,  1080] loss: 0.656 acc: 74.543\n","Train: [4,  1100] loss: 0.765 acc: 74.494\n","Train: [4,  1120] loss: 0.795 acc: 74.456\n","Train: [4,  1140] loss: 0.638 acc: 74.501\n","Train: [4,  1160] loss: 0.737 acc: 74.491\n","Train: [4,  1180] loss: 0.697 acc: 74.502\n","Train: [4,  1200] loss: 0.727 acc: 74.510\n","Train: [4,  1220] loss: 0.677 acc: 74.524\n","Train: [4,  1240] loss: 0.743 acc: 74.516\n","Train: [4,  1260] loss: 0.664 acc: 74.534\n","Train: [4,  1280] loss: 0.701 acc: 74.541\n","Train: [4,  1300] loss: 0.746 acc: 74.562\n","Train: [4,  1320] loss: 0.680 acc: 74.598\n","Train: [4,  1340] loss: 0.708 acc: 74.625\n","Train: [4,  1360] loss: 0.706 acc: 74.625\n","Train: [4,  1380] loss: 0.710 acc: 74.631\n","Train: [4,  1400] loss: 0.704 acc: 74.663\n","Train: [4,  1420] loss: 0.672 acc: 74.685\n","Train: [4,  1440] loss: 0.794 acc: 74.640\n","Train: [4,  1460] loss: 0.710 acc: 74.615\n","Train: [4,  1480] loss: 0.713 acc: 74.624\n","Train: [4,  1500] loss: 0.743 acc: 74.612\n","Train: [4,  1520] loss: 0.780 acc: 74.609\n","Train: [4,  1540] loss: 0.679 acc: 74.625\n","Train: [4,  1560] loss: 0.644 acc: 74.643\n","Test Accuracy: 72.770 %\n","Train: [5,    20] loss: 0.576 acc: 78.906\n","Train: [5,    40] loss: 0.637 acc: 77.578\n","Train: [5,    60] loss: 0.598 acc: 78.229\n","Train: [5,    80] loss: 0.633 acc: 78.438\n","Train: [5,   100] loss: 0.596 acc: 78.469\n","Train: [5,   120] loss: 0.554 acc: 78.490\n","Train: [5,   140] loss: 0.541 acc: 78.973\n","Train: [5,   160] loss: 0.611 acc: 78.770\n","Train: [5,   180] loss: 0.601 acc: 78.715\n","Train: [5,   200] loss: 0.611 acc: 78.734\n","Train: [5,   220] loss: 0.537 acc: 79.006\n","Train: [5,   240] loss: 0.691 acc: 78.763\n","Train: [5,   260] loss: 0.630 acc: 78.798\n","Train: [5,   280] loss: 0.581 acc: 78.795\n","Train: [5,   300] loss: 0.695 acc: 78.573\n","Train: [5,   320] loss: 0.552 acc: 78.809\n","Train: [5,   340] loss: 0.625 acc: 78.814\n","Train: [5,   360] loss: 0.634 acc: 78.785\n","Train: [5,   380] loss: 0.681 acc: 78.618\n","Train: [5,   400] loss: 0.613 acc: 78.688\n","Train: [5,   420] loss: 0.617 acc: 78.609\n","Train: [5,   440] loss: 0.624 acc: 78.572\n","Train: [5,   460] loss: 0.554 acc: 78.675\n","Train: [5,   480] loss: 0.588 acc: 78.620\n","Train: [5,   500] loss: 0.585 acc: 78.662\n","Train: [5,   520] loss: 0.663 acc: 78.582\n","Train: [5,   540] loss: 0.598 acc: 78.646\n","Train: [5,   560] loss: 0.599 acc: 78.622\n","Train: [5,   580] loss: 0.579 acc: 78.685\n","Train: [5,   600] loss: 0.676 acc: 78.635\n","Train: [5,   620] loss: 0.625 acc: 78.574\n","Train: [5,   640] loss: 0.608 acc: 78.618\n","Train: [5,   660] loss: 0.529 acc: 78.717\n","Train: [5,   680] loss: 0.603 acc: 78.727\n","Train: [5,   700] loss: 0.640 acc: 78.746\n","Train: [5,   720] loss: 0.547 acc: 78.811\n","Train: [5,   740] loss: 0.788 acc: 78.708\n","Train: [5,   760] loss: 0.667 acc: 78.655\n","Train: [5,   780] loss: 0.550 acc: 78.678\n","Train: [5,   800] loss: 0.553 acc: 78.734\n","Train: [5,   820] loss: 0.640 acc: 78.754\n","Train: [5,   840] loss: 0.580 acc: 78.739\n","Train: [5,   860] loss: 0.666 acc: 78.674\n","Train: [5,   880] loss: 0.657 acc: 78.619\n","Train: [5,   900] loss: 0.527 acc: 78.656\n","Train: [5,   920] loss: 0.609 acc: 78.668\n","Train: [5,   940] loss: 0.613 acc: 78.650\n","Train: [5,   960] loss: 0.634 acc: 78.626\n","Train: [5,   980] loss: 0.634 acc: 78.603\n","Train: [5,  1000] loss: 0.604 acc: 78.619\n","Train: [5,  1020] loss: 0.643 acc: 78.603\n","Train: [5,  1040] loss: 0.683 acc: 78.591\n","Train: [5,  1060] loss: 0.573 acc: 78.606\n","Train: [5,  1080] loss: 0.654 acc: 78.588\n","Train: [5,  1100] loss: 0.567 acc: 78.639\n","Train: [5,  1120] loss: 0.575 acc: 78.647\n","Train: [5,  1140] loss: 0.601 acc: 78.654\n","Train: [5,  1160] loss: 0.607 acc: 78.648\n","Train: [5,  1180] loss: 0.636 acc: 78.631\n","Train: [5,  1200] loss: 0.585 acc: 78.669\n","Train: [5,  1220] loss: 0.648 acc: 78.630\n","Train: [5,  1240] loss: 0.564 acc: 78.672\n","Train: [5,  1260] loss: 0.564 acc: 78.700\n","Train: [5,  1280] loss: 0.686 acc: 78.650\n","Train: [5,  1300] loss: 0.585 acc: 78.663\n","Train: [5,  1320] loss: 0.570 acc: 78.662\n","Train: [5,  1340] loss: 0.590 acc: 78.659\n","Train: [5,  1360] loss: 0.543 acc: 78.686\n","Train: [5,  1380] loss: 0.596 acc: 78.707\n","Train: [5,  1400] loss: 0.635 acc: 78.665\n","Train: [5,  1420] loss: 0.644 acc: 78.651\n","Train: [5,  1440] loss: 0.597 acc: 78.652\n","Train: [5,  1460] loss: 0.637 acc: 78.641\n","Train: [5,  1480] loss: 0.616 acc: 78.653\n","Train: [5,  1500] loss: 0.634 acc: 78.621\n","Train: [5,  1520] loss: 0.690 acc: 78.590\n","Train: [5,  1540] loss: 0.610 acc: 78.594\n","Train: [5,  1560] loss: 0.629 acc: 78.546\n","Test Accuracy: 73.690 %\n","Train: [6,    20] loss: 0.483 acc: 82.812\n","Train: [6,    40] loss: 0.526 acc: 82.031\n","Train: [6,    60] loss: 0.535 acc: 82.656\n","Train: [6,    80] loss: 0.468 acc: 83.125\n","Train: [6,   100] loss: 0.559 acc: 82.656\n","Train: [6,   120] loss: 0.488 acc: 82.578\n","Train: [6,   140] loss: 0.528 acc: 82.500\n","Train: [6,   160] loss: 0.509 acc: 82.539\n","Train: [6,   180] loss: 0.514 acc: 82.691\n","Train: [6,   200] loss: 0.511 acc: 82.531\n","Train: [6,   220] loss: 0.507 acc: 82.372\n","Train: [6,   240] loss: 0.473 acc: 82.578\n","Train: [6,   260] loss: 0.433 acc: 82.776\n","Train: [6,   280] loss: 0.510 acc: 82.623\n","Train: [6,   300] loss: 0.503 acc: 82.573\n","Train: [6,   320] loss: 0.451 acc: 82.773\n","Train: [6,   340] loss: 0.488 acc: 82.812\n","Train: [6,   360] loss: 0.524 acc: 82.786\n","Train: [6,   380] loss: 0.531 acc: 82.722\n","Train: [6,   400] loss: 0.499 acc: 82.672\n","Train: [6,   420] loss: 0.501 acc: 82.664\n","Train: [6,   440] loss: 0.475 acc: 82.720\n","Train: [6,   460] loss: 0.460 acc: 82.812\n","Train: [6,   480] loss: 0.535 acc: 82.760\n","Train: [6,   500] loss: 0.535 acc: 82.713\n","Train: [6,   520] loss: 0.535 acc: 82.650\n","Train: [6,   540] loss: 0.520 acc: 82.627\n","Train: [6,   560] loss: 0.536 acc: 82.623\n","Train: [6,   580] loss: 0.521 acc: 82.597\n","Train: [6,   600] loss: 0.532 acc: 82.620\n","Train: [6,   620] loss: 0.440 acc: 82.702\n","Train: [6,   640] loss: 0.528 acc: 82.666\n","Train: [6,   660] loss: 0.510 acc: 82.618\n","Train: [6,   680] loss: 0.477 acc: 82.661\n","Train: [6,   700] loss: 0.520 acc: 82.647\n","Train: [6,   720] loss: 0.527 acc: 82.587\n","Train: [6,   740] loss: 0.517 acc: 82.589\n","Train: [6,   760] loss: 0.470 acc: 82.664\n","Train: [6,   780] loss: 0.465 acc: 82.716\n","Train: [6,   800] loss: 0.520 acc: 82.664\n","Train: [6,   820] loss: 0.517 acc: 82.641\n","Train: [6,   840] loss: 0.502 acc: 82.623\n","Train: [6,   860] loss: 0.534 acc: 82.591\n","Train: [6,   880] loss: 0.547 acc: 82.553\n","Train: [6,   900] loss: 0.478 acc: 82.583\n","Train: [6,   920] loss: 0.576 acc: 82.507\n","Train: [6,   940] loss: 0.554 acc: 82.437\n","Train: [6,   960] loss: 0.542 acc: 82.367\n","Train: [6,   980] loss: 0.591 acc: 82.277\n","Train: [6,  1000] loss: 0.494 acc: 82.266\n","Train: [6,  1020] loss: 0.521 acc: 82.279\n","Train: [6,  1040] loss: 0.519 acc: 82.281\n","Train: [6,  1060] loss: 0.475 acc: 82.297\n","Train: [6,  1080] loss: 0.520 acc: 82.300\n","Train: [6,  1100] loss: 0.506 acc: 82.324\n","Train: [6,  1120] loss: 0.520 acc: 82.316\n","Train: [6,  1140] loss: 0.537 acc: 82.292\n","Train: [6,  1160] loss: 0.521 acc: 82.255\n","Train: [6,  1180] loss: 0.593 acc: 82.180\n","Train: [6,  1200] loss: 0.626 acc: 82.107\n","Train: [6,  1220] loss: 0.512 acc: 82.098\n","Train: [6,  1240] loss: 0.495 acc: 82.102\n","Train: [6,  1260] loss: 0.498 acc: 82.088\n","Train: [6,  1280] loss: 0.478 acc: 82.085\n","Train: [6,  1300] loss: 0.528 acc: 82.055\n","Train: [6,  1320] loss: 0.521 acc: 82.062\n","Train: [6,  1340] loss: 0.549 acc: 82.034\n","Train: [6,  1360] loss: 0.520 acc: 82.047\n","Train: [6,  1380] loss: 0.486 acc: 82.054\n","Train: [6,  1400] loss: 0.545 acc: 82.016\n","Train: [6,  1420] loss: 0.513 acc: 82.014\n","Train: [6,  1440] loss: 0.519 acc: 82.005\n","Train: [6,  1460] loss: 0.547 acc: 81.991\n","Train: [6,  1480] loss: 0.608 acc: 81.938\n","Train: [6,  1500] loss: 0.513 acc: 81.923\n","Train: [6,  1520] loss: 0.589 acc: 81.879\n","Train: [6,  1540] loss: 0.608 acc: 81.851\n","Train: [6,  1560] loss: 0.517 acc: 81.839\n","Test Accuracy: 75.730 %\n","Train: [7,    20] loss: 0.397 acc: 86.250\n","Train: [7,    40] loss: 0.379 acc: 86.016\n","Train: [7,    60] loss: 0.373 acc: 86.667\n","Train: [7,    80] loss: 0.404 acc: 86.523\n","Train: [7,   100] loss: 0.367 acc: 86.594\n","Train: [7,   120] loss: 0.444 acc: 85.990\n","Train: [7,   140] loss: 0.408 acc: 85.826\n","Train: [7,   160] loss: 0.407 acc: 85.840\n","Train: [7,   180] loss: 0.393 acc: 85.972\n","Train: [7,   200] loss: 0.396 acc: 85.984\n","Train: [7,   220] loss: 0.404 acc: 85.966\n","Train: [7,   240] loss: 0.400 acc: 86.055\n","Train: [7,   260] loss: 0.378 acc: 86.202\n","Train: [7,   280] loss: 0.392 acc: 86.194\n","Train: [7,   300] loss: 0.370 acc: 86.271\n","Train: [7,   320] loss: 0.429 acc: 86.182\n","Train: [7,   340] loss: 0.420 acc: 86.176\n","Train: [7,   360] loss: 0.445 acc: 86.120\n","Train: [7,   380] loss: 0.511 acc: 85.888\n","Train: [7,   400] loss: 0.431 acc: 85.758\n","Train: [7,   420] loss: 0.376 acc: 85.841\n","Train: [7,   440] loss: 0.403 acc: 85.852\n","Train: [7,   460] loss: 0.438 acc: 85.808\n","Train: [7,   480] loss: 0.428 acc: 85.749\n","Train: [7,   500] loss: 0.428 acc: 85.700\n","Train: [7,   520] loss: 0.431 acc: 85.703\n","Train: [7,   540] loss: 0.437 acc: 85.619\n","Train: [7,   560] loss: 0.403 acc: 85.664\n","Train: [7,   580] loss: 0.451 acc: 85.609\n","Train: [7,   600] loss: 0.394 acc: 85.615\n","Train: [7,   620] loss: 0.447 acc: 85.544\n","Train: [7,   640] loss: 0.416 acc: 85.542\n","Train: [7,   660] loss: 0.415 acc: 85.521\n","Train: [7,   680] loss: 0.428 acc: 85.528\n","Train: [7,   700] loss: 0.442 acc: 85.460\n","Train: [7,   720] loss: 0.407 acc: 85.469\n","Train: [7,   740] loss: 0.432 acc: 85.486\n","Train: [7,   760] loss: 0.472 acc: 85.444\n","Train: [7,   780] loss: 0.442 acc: 85.401\n","Train: [7,   800] loss: 0.463 acc: 85.363\n","Train: [7,   820] loss: 0.428 acc: 85.370\n","Train: [7,   840] loss: 0.477 acc: 85.309\n","Train: [7,   860] loss: 0.441 acc: 85.294\n","Train: [7,   880] loss: 0.477 acc: 85.263\n","Train: [7,   900] loss: 0.420 acc: 85.243\n","Train: [7,   920] loss: 0.378 acc: 85.268\n","Train: [7,   940] loss: 0.467 acc: 85.256\n","Train: [7,   960] loss: 0.454 acc: 85.238\n","Train: [7,   980] loss: 0.399 acc: 85.236\n","Train: [7,  1000] loss: 0.482 acc: 85.213\n","Train: [7,  1020] loss: 0.439 acc: 85.175\n","Train: [7,  1040] loss: 0.408 acc: 85.198\n","Train: [7,  1060] loss: 0.427 acc: 85.227\n","Train: [7,  1080] loss: 0.421 acc: 85.246\n","Train: [7,  1100] loss: 0.381 acc: 85.287\n","Train: [7,  1120] loss: 0.538 acc: 85.195\n","Train: [7,  1140] loss: 0.429 acc: 85.192\n","Train: [7,  1160] loss: 0.413 acc: 85.202\n","Train: [7,  1180] loss: 0.453 acc: 85.172\n","Train: [7,  1200] loss: 0.472 acc: 85.141\n","Train: [7,  1220] loss: 0.496 acc: 85.102\n","Train: [7,  1240] loss: 0.397 acc: 85.118\n","Train: [7,  1260] loss: 0.429 acc: 85.109\n","Train: [7,  1280] loss: 0.494 acc: 85.085\n","Train: [7,  1300] loss: 0.458 acc: 85.079\n","Train: [7,  1320] loss: 0.401 acc: 85.083\n","Train: [7,  1340] loss: 0.425 acc: 85.054\n","Train: [7,  1360] loss: 0.423 acc: 85.060\n","Train: [7,  1380] loss: 0.408 acc: 85.077\n","Train: [7,  1400] loss: 0.412 acc: 85.092\n","Train: [7,  1420] loss: 0.515 acc: 85.051\n","Train: [7,  1440] loss: 0.502 acc: 85.004\n","Train: [7,  1460] loss: 0.488 acc: 84.968\n","Train: [7,  1480] loss: 0.380 acc: 84.985\n","Train: [7,  1500] loss: 0.370 acc: 85.006\n","Train: [7,  1520] loss: 0.445 acc: 84.992\n","Train: [7,  1540] loss: 0.520 acc: 84.923\n","Train: [7,  1560] loss: 0.476 acc: 84.906\n","Test Accuracy: 75.250 %\n","Train: [8,    20] loss: 0.288 acc: 91.562\n","Train: [8,    40] loss: 0.337 acc: 89.766\n","Train: [8,    60] loss: 0.290 acc: 90.000\n","Train: [8,    80] loss: 0.293 acc: 90.039\n","Train: [8,   100] loss: 0.249 acc: 90.219\n","Train: [8,   120] loss: 0.298 acc: 90.286\n","Train: [8,   140] loss: 0.309 acc: 90.223\n","Train: [8,   160] loss: 0.320 acc: 90.020\n","Train: [8,   180] loss: 0.356 acc: 89.722\n","Train: [8,   200] loss: 0.332 acc: 89.672\n","Train: [8,   220] loss: 0.304 acc: 89.759\n","Train: [8,   240] loss: 0.373 acc: 89.583\n","Train: [8,   260] loss: 0.324 acc: 89.483\n","Train: [8,   280] loss: 0.310 acc: 89.364\n","Train: [8,   300] loss: 0.322 acc: 89.292\n","Train: [8,   320] loss: 0.353 acc: 89.189\n","Train: [8,   340] loss: 0.312 acc: 89.237\n","Train: [8,   360] loss: 0.317 acc: 89.314\n","Train: [8,   380] loss: 0.323 acc: 89.293\n","Train: [8,   400] loss: 0.364 acc: 89.180\n","Train: [8,   420] loss: 0.349 acc: 89.107\n","Train: [8,   440] loss: 0.299 acc: 89.105\n","Train: [8,   460] loss: 0.343 acc: 88.995\n","Train: [8,   480] loss: 0.335 acc: 88.900\n","Train: [8,   500] loss: 0.337 acc: 88.881\n","Train: [8,   520] loss: 0.371 acc: 88.774\n","Train: [8,   540] loss: 0.358 acc: 88.698\n","Train: [8,   560] loss: 0.362 acc: 88.655\n","Train: [8,   580] loss: 0.337 acc: 88.653\n","Train: [8,   600] loss: 0.349 acc: 88.609\n","Train: [8,   620] loss: 0.363 acc: 88.548\n","Train: [8,   640] loss: 0.368 acc: 88.481\n","Train: [8,   660] loss: 0.353 acc: 88.438\n","Train: [8,   680] loss: 0.359 acc: 88.359\n","Train: [8,   700] loss: 0.396 acc: 88.281\n","Train: [8,   720] loss: 0.281 acc: 88.351\n","Train: [8,   740] loss: 0.279 acc: 88.395\n","Train: [8,   760] loss: 0.345 acc: 88.376\n","Train: [8,   780] loss: 0.355 acc: 88.369\n","Train: [8,   800] loss: 0.365 acc: 88.289\n","Train: [8,   820] loss: 0.345 acc: 88.293\n","Train: [8,   840] loss: 0.357 acc: 88.263\n","Train: [8,   860] loss: 0.381 acc: 88.209\n","Train: [8,   880] loss: 0.365 acc: 88.161\n","Train: [8,   900] loss: 0.361 acc: 88.153\n","Train: [8,   920] loss: 0.356 acc: 88.149\n","Train: [8,   940] loss: 0.361 acc: 88.148\n","Train: [8,   960] loss: 0.400 acc: 88.125\n","Train: [8,   980] loss: 0.367 acc: 88.106\n","Train: [8,  1000] loss: 0.385 acc: 88.056\n","Train: [8,  1020] loss: 0.375 acc: 88.048\n","Train: [8,  1040] loss: 0.393 acc: 88.020\n","Train: [8,  1060] loss: 0.328 acc: 88.045\n","Train: [8,  1080] loss: 0.370 acc: 88.021\n","Train: [8,  1100] loss: 0.373 acc: 87.966\n","Train: [8,  1120] loss: 0.346 acc: 87.955\n","Train: [8,  1140] loss: 0.404 acc: 87.917\n","Train: [8,  1160] loss: 0.422 acc: 87.866\n","Train: [8,  1180] loss: 0.337 acc: 87.868\n","Train: [8,  1200] loss: 0.389 acc: 87.833\n","Train: [8,  1220] loss: 0.417 acc: 87.797\n","Train: [8,  1240] loss: 0.353 acc: 87.797\n","Train: [8,  1260] loss: 0.422 acc: 87.743\n","Train: [8,  1280] loss: 0.370 acc: 87.761\n","Train: [8,  1300] loss: 0.338 acc: 87.781\n","Train: [8,  1320] loss: 0.370 acc: 87.756\n","Train: [8,  1340] loss: 0.402 acc: 87.712\n","Train: [8,  1360] loss: 0.475 acc: 87.608\n","Train: [8,  1380] loss: 0.434 acc: 87.577\n","Train: [8,  1400] loss: 0.370 acc: 87.569\n","Train: [8,  1420] loss: 0.357 acc: 87.559\n","Train: [8,  1440] loss: 0.385 acc: 87.515\n","Train: [8,  1460] loss: 0.367 acc: 87.504\n","Train: [8,  1480] loss: 0.341 acc: 87.485\n","Train: [8,  1500] loss: 0.429 acc: 87.460\n","Train: [8,  1520] loss: 0.422 acc: 87.401\n","Train: [8,  1540] loss: 0.369 acc: 87.388\n","Train: [8,  1560] loss: 0.401 acc: 87.370\n","Test Accuracy: 75.310 %\n","Train: [9,    20] loss: 0.241 acc: 91.250\n","Train: [9,    40] loss: 0.338 acc: 89.609\n","Train: [9,    60] loss: 0.245 acc: 90.104\n","Train: [9,    80] loss: 0.270 acc: 90.312\n","Train: [9,   100] loss: 0.243 acc: 90.594\n","Train: [9,   120] loss: 0.246 acc: 90.781\n","Train: [9,   140] loss: 0.196 acc: 91.116\n","Train: [9,   160] loss: 0.219 acc: 91.328\n","Train: [9,   180] loss: 0.252 acc: 91.441\n","Train: [9,   200] loss: 0.257 acc: 91.438\n","Train: [9,   220] loss: 0.241 acc: 91.463\n","Train: [9,   240] loss: 0.249 acc: 91.471\n","Train: [9,   260] loss: 0.254 acc: 91.526\n","Train: [9,   280] loss: 0.222 acc: 91.607\n","Train: [9,   300] loss: 0.242 acc: 91.604\n","Train: [9,   320] loss: 0.252 acc: 91.582\n","Train: [9,   340] loss: 0.182 acc: 91.765\n","Train: [9,   360] loss: 0.259 acc: 91.719\n","Train: [9,   380] loss: 0.243 acc: 91.702\n","Train: [9,   400] loss: 0.310 acc: 91.594\n","Train: [9,   420] loss: 0.290 acc: 91.518\n","Train: [9,   440] loss: 0.303 acc: 91.449\n","Train: [9,   460] loss: 0.244 acc: 91.454\n","Train: [9,   480] loss: 0.263 acc: 91.445\n","Train: [9,   500] loss: 0.254 acc: 91.450\n","Train: [9,   520] loss: 0.277 acc: 91.448\n","Train: [9,   540] loss: 0.320 acc: 91.354\n","Train: [9,   560] loss: 0.273 acc: 91.295\n","Train: [9,   580] loss: 0.276 acc: 91.277\n","Train: [9,   600] loss: 0.213 acc: 91.323\n","Train: [9,   620] loss: 0.280 acc: 91.305\n","Train: [9,   640] loss: 0.243 acc: 91.333\n","Train: [9,   660] loss: 0.260 acc: 91.321\n","Train: [9,   680] loss: 0.283 acc: 91.278\n","Train: [9,   700] loss: 0.290 acc: 91.188\n","Train: [9,   720] loss: 0.350 acc: 91.076\n","Train: [9,   740] loss: 0.306 acc: 91.030\n","Train: [9,   760] loss: 0.297 acc: 91.012\n","Train: [9,   780] loss: 0.337 acc: 90.946\n","Train: [9,   800] loss: 0.360 acc: 90.883\n","Train: [9,   820] loss: 0.284 acc: 90.838\n","Train: [9,   840] loss: 0.299 acc: 90.796\n","Train: [9,   860] loss: 0.315 acc: 90.756\n","Train: [9,   880] loss: 0.290 acc: 90.728\n","Train: [9,   900] loss: 0.279 acc: 90.740\n","Train: [9,   920] loss: 0.341 acc: 90.707\n","Train: [9,   940] loss: 0.314 acc: 90.638\n","Train: [9,   960] loss: 0.312 acc: 90.592\n","Train: [9,   980] loss: 0.395 acc: 90.507\n","Train: [9,  1000] loss: 0.323 acc: 90.459\n","Train: [9,  1020] loss: 0.346 acc: 90.423\n","Train: [9,  1040] loss: 0.330 acc: 90.361\n","Train: [9,  1060] loss: 0.292 acc: 90.333\n","Train: [9,  1080] loss: 0.287 acc: 90.318\n","Train: [9,  1100] loss: 0.297 acc: 90.304\n","Train: [9,  1120] loss: 0.303 acc: 90.273\n","Train: [9,  1140] loss: 0.299 acc: 90.249\n","Train: [9,  1160] loss: 0.317 acc: 90.213\n","Train: [9,  1180] loss: 0.253 acc: 90.236\n","Train: [9,  1200] loss: 0.279 acc: 90.229\n","Train: [9,  1220] loss: 0.298 acc: 90.213\n","Train: [9,  1240] loss: 0.347 acc: 90.181\n","Train: [9,  1260] loss: 0.293 acc: 90.184\n","Train: [9,  1280] loss: 0.286 acc: 90.176\n","Train: [9,  1300] loss: 0.317 acc: 90.156\n","Train: [9,  1320] loss: 0.311 acc: 90.130\n","Train: [9,  1340] loss: 0.346 acc: 90.089\n","Train: [9,  1360] loss: 0.358 acc: 90.034\n","Train: [9,  1380] loss: 0.355 acc: 89.986\n","Train: [9,  1400] loss: 0.410 acc: 89.929\n","Train: [9,  1420] loss: 0.371 acc: 89.886\n","Train: [9,  1440] loss: 0.362 acc: 89.826\n","Train: [9,  1460] loss: 0.330 acc: 89.801\n","Train: [9,  1480] loss: 0.395 acc: 89.742\n","Train: [9,  1500] loss: 0.305 acc: 89.725\n","Train: [9,  1520] loss: 0.356 acc: 89.681\n","Train: [9,  1540] loss: 0.304 acc: 89.694\n","Train: [9,  1560] loss: 0.368 acc: 89.641\n","Test Accuracy: 75.300 %\n","Train: [10,    20] loss: 0.245 acc: 90.938\n","Train: [10,    40] loss: 0.218 acc: 91.719\n","Train: [10,    60] loss: 0.182 acc: 92.604\n","Train: [10,    80] loss: 0.161 acc: 93.086\n","Train: [10,   100] loss: 0.184 acc: 93.250\n","Train: [10,   120] loss: 0.175 acc: 93.385\n","Train: [10,   140] loss: 0.192 acc: 93.415\n","Train: [10,   160] loss: 0.181 acc: 93.457\n","Train: [10,   180] loss: 0.194 acc: 93.455\n","Train: [10,   200] loss: 0.191 acc: 93.484\n","Train: [10,   220] loss: 0.191 acc: 93.366\n","Train: [10,   240] loss: 0.169 acc: 93.477\n","Train: [10,   260] loss: 0.152 acc: 93.558\n","Train: [10,   280] loss: 0.169 acc: 93.583\n","Train: [10,   300] loss: 0.201 acc: 93.583\n","Train: [10,   320] loss: 0.204 acc: 93.623\n","Train: [10,   340] loss: 0.172 acc: 93.649\n","Train: [10,   360] loss: 0.176 acc: 93.655\n","Train: [10,   380] loss: 0.205 acc: 93.618\n","Train: [10,   400] loss: 0.201 acc: 93.570\n","Train: [10,   420] loss: 0.186 acc: 93.564\n","Train: [10,   440] loss: 0.240 acc: 93.480\n","Train: [10,   460] loss: 0.200 acc: 93.444\n","Train: [10,   480] loss: 0.193 acc: 93.444\n","Train: [10,   500] loss: 0.148 acc: 93.494\n","Train: [10,   520] loss: 0.207 acc: 93.510\n","Train: [10,   540] loss: 0.212 acc: 93.495\n","Train: [10,   560] loss: 0.202 acc: 93.493\n","Train: [10,   580] loss: 0.232 acc: 93.475\n","Train: [10,   600] loss: 0.226 acc: 93.427\n","Train: [10,   620] loss: 0.171 acc: 93.422\n","Train: [10,   640] loss: 0.185 acc: 93.403\n","Train: [10,   660] loss: 0.256 acc: 93.314\n","Train: [10,   680] loss: 0.254 acc: 93.226\n","Train: [10,   700] loss: 0.186 acc: 93.214\n","Train: [10,   720] loss: 0.206 acc: 93.186\n","Train: [10,   740] loss: 0.299 acc: 93.100\n","Train: [10,   760] loss: 0.266 acc: 93.039\n","Train: [10,   780] loss: 0.282 acc: 92.957\n","Train: [10,   800] loss: 0.250 acc: 92.910\n","Train: [10,   820] loss: 0.202 acc: 92.919\n","Train: [10,   840] loss: 0.242 acc: 92.902\n","Train: [10,   860] loss: 0.241 acc: 92.838\n","Train: [10,   880] loss: 0.200 acc: 92.855\n","Train: [10,   900] loss: 0.179 acc: 92.865\n","Train: [10,   920] loss: 0.224 acc: 92.867\n","Train: [10,   940] loss: 0.243 acc: 92.829\n","Train: [10,   960] loss: 0.293 acc: 92.783\n","Train: [10,   980] loss: 0.276 acc: 92.723\n","Train: [10,  1000] loss: 0.273 acc: 92.678\n","Train: [10,  1020] loss: 0.222 acc: 92.669\n","Train: [10,  1040] loss: 0.235 acc: 92.635\n","Train: [10,  1060] loss: 0.206 acc: 92.659\n","Train: [10,  1080] loss: 0.289 acc: 92.613\n","Train: [10,  1100] loss: 0.216 acc: 92.597\n","Train: [10,  1120] loss: 0.266 acc: 92.550\n","Train: [10,  1140] loss: 0.332 acc: 92.448\n","Train: [10,  1160] loss: 0.241 acc: 92.433\n","Train: [10,  1180] loss: 0.255 acc: 92.421\n","Train: [10,  1200] loss: 0.334 acc: 92.359\n","Train: [10,  1220] loss: 0.228 acc: 92.351\n","Train: [10,  1240] loss: 0.253 acc: 92.336\n","Train: [10,  1260] loss: 0.290 acc: 92.312\n","Train: [10,  1280] loss: 0.256 acc: 92.283\n","Train: [10,  1300] loss: 0.311 acc: 92.243\n","Train: [10,  1320] loss: 0.306 acc: 92.190\n","Train: [10,  1340] loss: 0.293 acc: 92.162\n","Train: [10,  1360] loss: 0.294 acc: 92.128\n","Train: [10,  1380] loss: 0.271 acc: 92.088\n","Train: [10,  1400] loss: 0.260 acc: 92.058\n","Train: [10,  1420] loss: 0.306 acc: 92.022\n","Train: [10,  1440] loss: 0.288 acc: 92.001\n","Train: [10,  1460] loss: 0.257 acc: 91.993\n","Train: [10,  1480] loss: 0.260 acc: 91.966\n","Train: [10,  1500] loss: 0.234 acc: 91.963\n","Train: [10,  1520] loss: 0.295 acc: 91.939\n","Train: [10,  1540] loss: 0.289 acc: 91.922\n","Train: [10,  1560] loss: 0.259 acc: 91.901\n","Test Accuracy: 74.980 %\n","Train: [11,    20] loss: 0.157 acc: 93.594\n","Train: [11,    40] loss: 0.164 acc: 93.984\n","Train: [11,    60] loss: 0.173 acc: 93.906\n","Train: [11,    80] loss: 0.147 acc: 94.180\n","Train: [11,   100] loss: 0.173 acc: 94.281\n","Train: [11,   120] loss: 0.175 acc: 94.141\n","Train: [11,   140] loss: 0.202 acc: 93.884\n","Train: [11,   160] loss: 0.194 acc: 93.906\n","Train: [11,   180] loss: 0.175 acc: 93.941\n","Train: [11,   200] loss: 0.154 acc: 93.984\n","Train: [11,   220] loss: 0.135 acc: 94.105\n","Train: [11,   240] loss: 0.175 acc: 94.089\n","Train: [11,   260] loss: 0.144 acc: 94.171\n","Train: [11,   280] loss: 0.191 acc: 94.062\n","Train: [11,   300] loss: 0.122 acc: 94.198\n","Train: [11,   320] loss: 0.109 acc: 94.385\n","Train: [11,   340] loss: 0.117 acc: 94.522\n","Train: [11,   360] loss: 0.129 acc: 94.557\n","Train: [11,   380] loss: 0.151 acc: 94.581\n","Train: [11,   400] loss: 0.180 acc: 94.508\n","Train: [11,   420] loss: 0.160 acc: 94.509\n","Train: [11,   440] loss: 0.131 acc: 94.574\n","Train: [11,   460] loss: 0.124 acc: 94.633\n","Train: [11,   480] loss: 0.132 acc: 94.635\n","Train: [11,   500] loss: 0.163 acc: 94.612\n","Train: [11,   520] loss: 0.142 acc: 94.615\n","Train: [11,   540] loss: 0.144 acc: 94.618\n","Train: [11,   560] loss: 0.195 acc: 94.598\n","Train: [11,   580] loss: 0.151 acc: 94.591\n","Train: [11,   600] loss: 0.146 acc: 94.578\n","Train: [11,   620] loss: 0.178 acc: 94.551\n","Train: [11,   640] loss: 0.168 acc: 94.556\n","Train: [11,   660] loss: 0.185 acc: 94.560\n","Train: [11,   680] loss: 0.176 acc: 94.531\n","Train: [11,   700] loss: 0.233 acc: 94.433\n","Train: [11,   720] loss: 0.211 acc: 94.375\n","Train: [11,   740] loss: 0.218 acc: 94.324\n","Train: [11,   760] loss: 0.217 acc: 94.243\n","Train: [11,   780] loss: 0.230 acc: 94.163\n","Train: [11,   800] loss: 0.177 acc: 94.152\n","Train: [11,   820] loss: 0.216 acc: 94.101\n","Train: [11,   840] loss: 0.157 acc: 94.111\n","Train: [11,   860] loss: 0.242 acc: 94.059\n","Train: [11,   880] loss: 0.216 acc: 93.999\n","Train: [11,   900] loss: 0.192 acc: 93.983\n","Train: [11,   920] loss: 0.210 acc: 93.940\n","Train: [11,   940] loss: 0.165 acc: 93.933\n","Train: [11,   960] loss: 0.195 acc: 93.936\n","Train: [11,   980] loss: 0.223 acc: 93.893\n","Train: [11,  1000] loss: 0.237 acc: 93.869\n","Train: [11,  1020] loss: 0.209 acc: 93.836\n","Train: [11,  1040] loss: 0.183 acc: 93.831\n","Train: [11,  1060] loss: 0.223 acc: 93.797\n","Train: [11,  1080] loss: 0.205 acc: 93.764\n","Train: [11,  1100] loss: 0.151 acc: 93.784\n","Train: [11,  1120] loss: 0.161 acc: 93.783\n","Train: [11,  1140] loss: 0.190 acc: 93.780\n","Train: [11,  1160] loss: 0.224 acc: 93.728\n","Train: [11,  1180] loss: 0.176 acc: 93.731\n","Train: [11,  1200] loss: 0.204 acc: 93.706\n","Train: [11,  1220] loss: 0.203 acc: 93.694\n","Train: [11,  1240] loss: 0.217 acc: 93.672\n","Train: [11,  1260] loss: 0.207 acc: 93.663\n","Train: [11,  1280] loss: 0.226 acc: 93.630\n","Train: [11,  1300] loss: 0.272 acc: 93.572\n","Train: [11,  1320] loss: 0.226 acc: 93.542\n","Train: [11,  1340] loss: 0.210 acc: 93.531\n","Train: [11,  1360] loss: 0.254 acc: 93.493\n","Train: [11,  1380] loss: 0.253 acc: 93.456\n","Train: [11,  1400] loss: 0.282 acc: 93.408\n","Train: [11,  1420] loss: 0.208 acc: 93.389\n","Train: [11,  1440] loss: 0.263 acc: 93.359\n","Train: [11,  1460] loss: 0.267 acc: 93.315\n","Train: [11,  1480] loss: 0.272 acc: 93.285\n","Train: [11,  1500] loss: 0.242 acc: 93.275\n","Train: [11,  1520] loss: 0.239 acc: 93.259\n","Train: [11,  1540] loss: 0.233 acc: 93.233\n","Train: [11,  1560] loss: 0.253 acc: 93.211\n","Test Accuracy: 75.630 %\n","Train: [12,    20] loss: 0.151 acc: 94.531\n","Train: [12,    40] loss: 0.167 acc: 93.438\n","Train: [12,    60] loss: 0.130 acc: 94.167\n","Train: [12,    80] loss: 0.133 acc: 94.414\n","Train: [12,   100] loss: 0.087 acc: 95.062\n","Train: [12,   120] loss: 0.112 acc: 95.339\n","Train: [12,   140] loss: 0.163 acc: 95.223\n","Train: [12,   160] loss: 0.127 acc: 95.195\n","Train: [12,   180] loss: 0.113 acc: 95.330\n","Train: [12,   200] loss: 0.122 acc: 95.359\n","Train: [12,   220] loss: 0.149 acc: 95.270\n","Train: [12,   240] loss: 0.158 acc: 95.273\n","Train: [12,   260] loss: 0.151 acc: 95.240\n","Train: [12,   280] loss: 0.145 acc: 95.268\n","Train: [12,   300] loss: 0.176 acc: 95.156\n","Train: [12,   320] loss: 0.153 acc: 95.107\n","Train: [12,   340] loss: 0.145 acc: 95.119\n","Train: [12,   360] loss: 0.103 acc: 95.191\n","Train: [12,   380] loss: 0.182 acc: 95.148\n","Train: [12,   400] loss: 0.145 acc: 95.102\n","Train: [12,   420] loss: 0.127 acc: 95.119\n","Train: [12,   440] loss: 0.161 acc: 95.028\n","Train: [12,   460] loss: 0.129 acc: 95.020\n","Train: [12,   480] loss: 0.155 acc: 95.007\n","Train: [12,   500] loss: 0.131 acc: 95.019\n","Train: [12,   520] loss: 0.116 acc: 95.054\n","Train: [12,   540] loss: 0.135 acc: 95.064\n","Train: [12,   560] loss: 0.128 acc: 95.078\n","Train: [12,   580] loss: 0.116 acc: 95.097\n","Train: [12,   600] loss: 0.145 acc: 95.078\n","Train: [12,   620] loss: 0.139 acc: 95.076\n","Train: [12,   640] loss: 0.111 acc: 95.132\n","Train: [12,   660] loss: 0.132 acc: 95.114\n","Train: [12,   680] loss: 0.141 acc: 95.110\n","Train: [12,   700] loss: 0.150 acc: 95.089\n","Train: [12,   720] loss: 0.168 acc: 95.043\n","Train: [12,   740] loss: 0.147 acc: 95.017\n","Train: [12,   760] loss: 0.168 acc: 94.979\n","Train: [12,   780] loss: 0.127 acc: 94.996\n","Train: [12,   800] loss: 0.140 acc: 94.992\n","Train: [12,   820] loss: 0.173 acc: 94.950\n","Train: [12,   840] loss: 0.197 acc: 94.903\n","Train: [12,   860] loss: 0.193 acc: 94.836\n","Train: [12,   880] loss: 0.203 acc: 94.794\n","Train: [12,   900] loss: 0.168 acc: 94.795\n","Train: [12,   920] loss: 0.192 acc: 94.728\n","Train: [12,   940] loss: 0.167 acc: 94.701\n","Train: [12,   960] loss: 0.199 acc: 94.652\n","Train: [12,   980] loss: 0.145 acc: 94.656\n","Train: [12,  1000] loss: 0.169 acc: 94.641\n","Train: [12,  1020] loss: 0.179 acc: 94.623\n","Train: [12,  1040] loss: 0.184 acc: 94.606\n","Train: [12,  1060] loss: 0.178 acc: 94.593\n","Train: [12,  1080] loss: 0.197 acc: 94.557\n","Train: [12,  1100] loss: 0.207 acc: 94.526\n","Train: [12,  1120] loss: 0.212 acc: 94.495\n","Train: [12,  1140] loss: 0.230 acc: 94.454\n","Train: [12,  1160] loss: 0.227 acc: 94.418\n","Train: [12,  1180] loss: 0.205 acc: 94.383\n","Train: [12,  1200] loss: 0.236 acc: 94.333\n","Train: [12,  1220] loss: 0.176 acc: 94.324\n","Train: [12,  1240] loss: 0.216 acc: 94.282\n","Train: [12,  1260] loss: 0.164 acc: 94.286\n","Train: [12,  1280] loss: 0.159 acc: 94.260\n","Train: [12,  1300] loss: 0.168 acc: 94.262\n","Train: [12,  1320] loss: 0.124 acc: 94.278\n","Train: [12,  1340] loss: 0.202 acc: 94.249\n","Train: [12,  1360] loss: 0.168 acc: 94.256\n","Train: [12,  1380] loss: 0.195 acc: 94.232\n","Train: [12,  1400] loss: 0.221 acc: 94.194\n","Train: [12,  1420] loss: 0.216 acc: 94.162\n","Train: [12,  1440] loss: 0.258 acc: 94.106\n","Train: [12,  1460] loss: 0.225 acc: 94.086\n","Train: [12,  1480] loss: 0.177 acc: 94.088\n","Train: [12,  1500] loss: 0.156 acc: 94.098\n","Train: [12,  1520] loss: 0.209 acc: 94.075\n","Train: [12,  1540] loss: 0.211 acc: 94.050\n","Train: [12,  1560] loss: 0.194 acc: 94.040\n","Test Accuracy: 75.710 %\n","Train: [13,    20] loss: 0.082 acc: 97.344\n","Train: [13,    40] loss: 0.096 acc: 96.641\n","Train: [13,    60] loss: 0.089 acc: 96.667\n","Train: [13,    80] loss: 0.082 acc: 96.797\n","Train: [13,   100] loss: 0.072 acc: 96.719\n","Train: [13,   120] loss: 0.092 acc: 96.693\n","Train: [13,   140] loss: 0.090 acc: 96.741\n","Train: [13,   160] loss: 0.104 acc: 96.738\n","Train: [13,   180] loss: 0.084 acc: 96.684\n","Train: [13,   200] loss: 0.084 acc: 96.766\n","Train: [13,   220] loss: 0.114 acc: 96.662\n","Train: [13,   240] loss: 0.119 acc: 96.576\n","Train: [13,   260] loss: 0.093 acc: 96.635\n","Train: [13,   280] loss: 0.134 acc: 96.496\n","Train: [13,   300] loss: 0.154 acc: 96.354\n","Train: [13,   320] loss: 0.090 acc: 96.396\n","Train: [13,   340] loss: 0.083 acc: 96.443\n","Train: [13,   360] loss: 0.115 acc: 96.432\n","Train: [13,   380] loss: 0.141 acc: 96.365\n","Train: [13,   400] loss: 0.119 acc: 96.297\n","Train: [13,   420] loss: 0.105 acc: 96.265\n","Train: [13,   440] loss: 0.084 acc: 96.278\n","Train: [13,   460] loss: 0.082 acc: 96.338\n","Train: [13,   480] loss: 0.129 acc: 96.296\n","Train: [13,   500] loss: 0.131 acc: 96.231\n","Train: [13,   520] loss: 0.160 acc: 96.196\n","Train: [13,   540] loss: 0.139 acc: 96.163\n","Train: [13,   560] loss: 0.173 acc: 96.099\n","Train: [13,   580] loss: 0.143 acc: 96.061\n","Train: [13,   600] loss: 0.141 acc: 96.031\n","Train: [13,   620] loss: 0.136 acc: 95.998\n","Train: [13,   640] loss: 0.118 acc: 95.962\n","Train: [13,   660] loss: 0.140 acc: 95.947\n","Train: [13,   680] loss: 0.153 acc: 95.887\n","Train: [13,   700] loss: 0.084 acc: 95.924\n","Train: [13,   720] loss: 0.145 acc: 95.842\n","Train: [13,   740] loss: 0.114 acc: 95.853\n","Train: [13,   760] loss: 0.142 acc: 95.851\n","Train: [13,   780] loss: 0.133 acc: 95.817\n","Train: [13,   800] loss: 0.159 acc: 95.805\n","Train: [13,   820] loss: 0.116 acc: 95.800\n","Train: [13,   840] loss: 0.139 acc: 95.766\n","Train: [13,   860] loss: 0.158 acc: 95.741\n","Train: [13,   880] loss: 0.177 acc: 95.682\n","Train: [13,   900] loss: 0.186 acc: 95.639\n","Train: [13,   920] loss: 0.173 acc: 95.605\n","Train: [13,   940] loss: 0.153 acc: 95.575\n","Train: [13,   960] loss: 0.153 acc: 95.560\n","Train: [13,   980] loss: 0.159 acc: 95.542\n","Train: [13,  1000] loss: 0.132 acc: 95.534\n","Train: [13,  1020] loss: 0.104 acc: 95.533\n","Train: [13,  1040] loss: 0.094 acc: 95.571\n","Train: [13,  1060] loss: 0.168 acc: 95.551\n","Train: [13,  1080] loss: 0.091 acc: 95.556\n","Train: [13,  1100] loss: 0.164 acc: 95.540\n","Train: [13,  1120] loss: 0.155 acc: 95.525\n","Train: [13,  1140] loss: 0.135 acc: 95.521\n","Train: [13,  1160] loss: 0.163 acc: 95.485\n","Train: [13,  1180] loss: 0.131 acc: 95.482\n","Train: [13,  1200] loss: 0.186 acc: 95.448\n","Train: [13,  1220] loss: 0.144 acc: 95.423\n","Train: [13,  1240] loss: 0.166 acc: 95.403\n","Train: [13,  1260] loss: 0.165 acc: 95.389\n","Train: [13,  1280] loss: 0.169 acc: 95.359\n","Train: [13,  1300] loss: 0.161 acc: 95.341\n","Train: [13,  1320] loss: 0.166 acc: 95.320\n","Train: [13,  1340] loss: 0.139 acc: 95.324\n","Train: [13,  1360] loss: 0.111 acc: 95.340\n","Train: [13,  1380] loss: 0.158 acc: 95.319\n","Train: [13,  1400] loss: 0.154 acc: 95.299\n","Train: [13,  1420] loss: 0.168 acc: 95.288\n","Train: [13,  1440] loss: 0.185 acc: 95.273\n","Train: [13,  1460] loss: 0.158 acc: 95.265\n","Train: [13,  1480] loss: 0.120 acc: 95.272\n","Train: [13,  1500] loss: 0.137 acc: 95.271\n","Train: [13,  1520] loss: 0.154 acc: 95.267\n","Train: [13,  1540] loss: 0.180 acc: 95.244\n","Train: [13,  1560] loss: 0.169 acc: 95.220\n","Test Accuracy: 74.390 %\n","Train: [14,    20] loss: 0.095 acc: 97.188\n","Train: [14,    40] loss: 0.098 acc: 96.953\n","Train: [14,    60] loss: 0.098 acc: 96.771\n","Train: [14,    80] loss: 0.126 acc: 96.445\n","Train: [14,   100] loss: 0.121 acc: 96.438\n","Train: [14,   120] loss: 0.085 acc: 96.458\n","Train: [14,   140] loss: 0.079 acc: 96.674\n","Train: [14,   160] loss: 0.075 acc: 96.758\n","Train: [14,   180] loss: 0.099 acc: 96.753\n","Train: [14,   200] loss: 0.119 acc: 96.719\n","Train: [14,   220] loss: 0.118 acc: 96.690\n","Train: [14,   240] loss: 0.094 acc: 96.797\n","Train: [14,   260] loss: 0.085 acc: 96.827\n","Train: [14,   280] loss: 0.103 acc: 96.763\n","Train: [14,   300] loss: 0.094 acc: 96.812\n","Train: [14,   320] loss: 0.084 acc: 96.855\n","Train: [14,   340] loss: 0.066 acc: 96.875\n","Train: [14,   360] loss: 0.120 acc: 96.806\n","Train: [14,   380] loss: 0.071 acc: 96.817\n","Train: [14,   400] loss: 0.091 acc: 96.820\n","Train: [14,   420] loss: 0.081 acc: 96.860\n","Train: [14,   440] loss: 0.095 acc: 96.825\n","Train: [14,   460] loss: 0.094 acc: 96.848\n","Train: [14,   480] loss: 0.087 acc: 96.862\n","Train: [14,   500] loss: 0.138 acc: 96.781\n","Train: [14,   520] loss: 0.094 acc: 96.797\n","Train: [14,   540] loss: 0.110 acc: 96.782\n","Train: [14,   560] loss: 0.110 acc: 96.758\n","Train: [14,   580] loss: 0.083 acc: 96.773\n","Train: [14,   600] loss: 0.162 acc: 96.719\n","Train: [14,   620] loss: 0.126 acc: 96.678\n","Train: [14,   640] loss: 0.094 acc: 96.660\n","Train: [14,   660] loss: 0.110 acc: 96.652\n","Train: [14,   680] loss: 0.097 acc: 96.645\n","Train: [14,   700] loss: 0.118 acc: 96.621\n","Train: [14,   720] loss: 0.118 acc: 96.580\n","Train: [14,   740] loss: 0.122 acc: 96.562\n","Train: [14,   760] loss: 0.127 acc: 96.538\n","Train: [14,   780] loss: 0.080 acc: 96.546\n","Train: [14,   800] loss: 0.113 acc: 96.539\n","Train: [14,   820] loss: 0.138 acc: 96.517\n","Train: [14,   840] loss: 0.101 acc: 96.525\n","Train: [14,   860] loss: 0.134 acc: 96.497\n","Train: [14,   880] loss: 0.125 acc: 96.474\n","Train: [14,   900] loss: 0.123 acc: 96.472\n","Train: [14,   920] loss: 0.188 acc: 96.396\n","Train: [14,   940] loss: 0.133 acc: 96.346\n","Train: [14,   960] loss: 0.160 acc: 96.305\n","Train: [14,   980] loss: 0.191 acc: 96.250\n","Train: [14,  1000] loss: 0.096 acc: 96.247\n","Train: [14,  1020] loss: 0.116 acc: 96.244\n","Train: [14,  1040] loss: 0.111 acc: 96.241\n","Train: [14,  1060] loss: 0.143 acc: 96.206\n","Train: [14,  1080] loss: 0.117 acc: 96.209\n","Train: [14,  1100] loss: 0.140 acc: 96.185\n","Train: [14,  1120] loss: 0.107 acc: 96.197\n","Train: [14,  1140] loss: 0.152 acc: 96.162\n","Train: [14,  1160] loss: 0.107 acc: 96.158\n","Train: [14,  1180] loss: 0.129 acc: 96.141\n","Train: [14,  1200] loss: 0.121 acc: 96.135\n","Train: [14,  1220] loss: 0.120 acc: 96.114\n","Train: [14,  1240] loss: 0.095 acc: 96.119\n","Train: [14,  1260] loss: 0.117 acc: 96.111\n","Train: [14,  1280] loss: 0.115 acc: 96.086\n","Train: [14,  1300] loss: 0.156 acc: 96.050\n","Train: [14,  1320] loss: 0.114 acc: 96.046\n","Train: [14,  1340] loss: 0.130 acc: 96.040\n","Train: [14,  1360] loss: 0.149 acc: 96.023\n","Train: [14,  1380] loss: 0.152 acc: 95.992\n","Train: [14,  1400] loss: 0.189 acc: 95.955\n","Train: [14,  1420] loss: 0.188 acc: 95.915\n","Train: [14,  1440] loss: 0.171 acc: 95.907\n","Train: [14,  1460] loss: 0.145 acc: 95.884\n","Train: [14,  1480] loss: 0.109 acc: 95.889\n","Train: [14,  1500] loss: 0.156 acc: 95.869\n","Train: [14,  1520] loss: 0.104 acc: 95.863\n","Train: [14,  1540] loss: 0.125 acc: 95.848\n","Train: [14,  1560] loss: 0.152 acc: 95.827\n","Test Accuracy: 75.810 %\n","Train: [15,    20] loss: 0.070 acc: 98.281\n","Train: [15,    40] loss: 0.085 acc: 97.578\n","Train: [15,    60] loss: 0.071 acc: 97.708\n","Train: [15,    80] loss: 0.083 acc: 97.539\n","Train: [15,   100] loss: 0.067 acc: 97.500\n","Train: [15,   120] loss: 0.048 acc: 97.682\n","Train: [15,   140] loss: 0.036 acc: 97.879\n","Train: [15,   160] loss: 0.042 acc: 97.910\n","Train: [15,   180] loss: 0.061 acc: 97.830\n","Train: [15,   200] loss: 0.061 acc: 97.875\n","Train: [15,   220] loss: 0.104 acc: 97.699\n","Train: [15,   240] loss: 0.063 acc: 97.695\n","Train: [15,   260] loss: 0.062 acc: 97.680\n","Train: [15,   280] loss: 0.085 acc: 97.634\n","Train: [15,   300] loss: 0.087 acc: 97.573\n","Train: [15,   320] loss: 0.087 acc: 97.510\n","Train: [15,   340] loss: 0.100 acc: 97.472\n","Train: [15,   360] loss: 0.083 acc: 97.422\n","Train: [15,   380] loss: 0.099 acc: 97.377\n","Train: [15,   400] loss: 0.094 acc: 97.352\n","Train: [15,   420] loss: 0.124 acc: 97.262\n","Train: [15,   440] loss: 0.089 acc: 97.237\n","Train: [15,   460] loss: 0.116 acc: 97.167\n","Train: [15,   480] loss: 0.099 acc: 97.155\n","Train: [15,   500] loss: 0.078 acc: 97.169\n","Train: [15,   520] loss: 0.115 acc: 97.103\n","Train: [15,   540] loss: 0.082 acc: 97.112\n","Train: [15,   560] loss: 0.092 acc: 97.098\n","Train: [15,   580] loss: 0.071 acc: 97.123\n","Train: [15,   600] loss: 0.083 acc: 97.115\n","Train: [15,   620] loss: 0.108 acc: 97.082\n","Train: [15,   640] loss: 0.095 acc: 97.080\n","Train: [15,   660] loss: 0.079 acc: 97.107\n","Train: [15,   680] loss: 0.078 acc: 97.119\n","Train: [15,   700] loss: 0.082 acc: 97.125\n","Train: [15,   720] loss: 0.065 acc: 97.135\n","Train: [15,   740] loss: 0.078 acc: 97.111\n","Train: [15,   760] loss: 0.091 acc: 97.097\n","Train: [15,   780] loss: 0.115 acc: 97.075\n","Train: [15,   800] loss: 0.140 acc: 97.035\n","Train: [15,   820] loss: 0.084 acc: 97.043\n","Train: [15,   840] loss: 0.101 acc: 97.035\n","Train: [15,   860] loss: 0.087 acc: 97.020\n","Train: [15,   880] loss: 0.103 acc: 96.996\n","Train: [15,   900] loss: 0.082 acc: 97.007\n","Train: [15,   920] loss: 0.098 acc: 96.997\n","Train: [15,   940] loss: 0.129 acc: 96.968\n","Train: [15,   960] loss: 0.091 acc: 96.950\n","Train: [15,   980] loss: 0.109 acc: 96.920\n","Train: [15,  1000] loss: 0.104 acc: 96.909\n","Train: [15,  1020] loss: 0.116 acc: 96.893\n","Train: [15,  1040] loss: 0.131 acc: 96.860\n","Train: [15,  1060] loss: 0.164 acc: 96.828\n","Train: [15,  1080] loss: 0.140 acc: 96.791\n","Train: [15,  1100] loss: 0.112 acc: 96.778\n","Train: [15,  1120] loss: 0.150 acc: 96.733\n","Train: [15,  1140] loss: 0.104 acc: 96.716\n","Train: [15,  1160] loss: 0.108 acc: 96.705\n","Train: [15,  1180] loss: 0.107 acc: 96.690\n","Train: [15,  1200] loss: 0.121 acc: 96.680\n","Train: [15,  1220] loss: 0.124 acc: 96.668\n","Train: [15,  1240] loss: 0.124 acc: 96.658\n","Train: [15,  1260] loss: 0.115 acc: 96.644\n","Train: [15,  1280] loss: 0.161 acc: 96.619\n","Train: [15,  1300] loss: 0.105 acc: 96.618\n","Train: [15,  1320] loss: 0.152 acc: 96.607\n","Train: [15,  1340] loss: 0.128 acc: 96.586\n","Train: [15,  1360] loss: 0.117 acc: 96.576\n","Train: [15,  1380] loss: 0.094 acc: 96.574\n","Train: [15,  1400] loss: 0.108 acc: 96.562\n","Train: [15,  1420] loss: 0.116 acc: 96.556\n","Train: [15,  1440] loss: 0.126 acc: 96.534\n","Train: [15,  1460] loss: 0.184 acc: 96.496\n","Train: [15,  1480] loss: 0.115 acc: 96.489\n","Train: [15,  1500] loss: 0.099 acc: 96.479\n","Train: [15,  1520] loss: 0.151 acc: 96.454\n","Train: [15,  1540] loss: 0.137 acc: 96.443\n","Train: [15,  1560] loss: 0.154 acc: 96.434\n","Test Accuracy: 74.470 %\n","Train: [16,    20] loss: 0.113 acc: 96.406\n","Train: [16,    40] loss: 0.088 acc: 96.484\n","Train: [16,    60] loss: 0.082 acc: 96.562\n","Train: [16,    80] loss: 0.084 acc: 96.875\n","Train: [16,   100] loss: 0.124 acc: 96.594\n","Train: [16,   120] loss: 0.118 acc: 96.536\n","Train: [16,   140] loss: 0.099 acc: 96.629\n","Train: [16,   160] loss: 0.064 acc: 96.699\n","Train: [16,   180] loss: 0.089 acc: 96.701\n","Train: [16,   200] loss: 0.063 acc: 96.797\n","Train: [16,   220] loss: 0.081 acc: 96.790\n","Train: [16,   240] loss: 0.070 acc: 96.875\n","Train: [16,   260] loss: 0.106 acc: 96.851\n","Train: [16,   280] loss: 0.094 acc: 96.864\n","Train: [16,   300] loss: 0.102 acc: 96.781\n","Train: [16,   320] loss: 0.060 acc: 96.875\n","Train: [16,   340] loss: 0.063 acc: 96.912\n","Train: [16,   360] loss: 0.062 acc: 96.979\n","Train: [16,   380] loss: 0.087 acc: 96.982\n","Train: [16,   400] loss: 0.098 acc: 97.000\n","Train: [16,   420] loss: 0.101 acc: 96.964\n","Train: [16,   440] loss: 0.081 acc: 96.982\n","Train: [16,   460] loss: 0.103 acc: 96.963\n","Train: [16,   480] loss: 0.049 acc: 97.031\n","Train: [16,   500] loss: 0.109 acc: 97.006\n","Train: [16,   520] loss: 0.065 acc: 97.061\n","Train: [16,   540] loss: 0.081 acc: 97.066\n","Train: [16,   560] loss: 0.086 acc: 97.070\n","Train: [16,   580] loss: 0.114 acc: 97.037\n","Train: [16,   600] loss: 0.090 acc: 97.042\n","Train: [16,   620] loss: 0.134 acc: 96.996\n","Train: [16,   640] loss: 0.124 acc: 96.963\n","Train: [16,   660] loss: 0.094 acc: 96.941\n","Train: [16,   680] loss: 0.094 acc: 96.935\n","Train: [16,   700] loss: 0.080 acc: 96.955\n","Train: [16,   720] loss: 0.102 acc: 96.931\n","Train: [16,   740] loss: 0.059 acc: 96.968\n","Train: [16,   760] loss: 0.088 acc: 96.965\n","Train: [16,   780] loss: 0.100 acc: 96.955\n","Train: [16,   800] loss: 0.070 acc: 96.965\n","Train: [16,   820] loss: 0.081 acc: 96.951\n","Train: [16,   840] loss: 0.103 acc: 96.931\n","Train: [16,   860] loss: 0.108 acc: 96.900\n","Train: [16,   880] loss: 0.112 acc: 96.886\n","Train: [16,   900] loss: 0.138 acc: 96.861\n","Train: [16,   920] loss: 0.102 acc: 96.838\n","Train: [16,   940] loss: 0.151 acc: 96.802\n","Train: [16,   960] loss: 0.138 acc: 96.764\n","Train: [16,   980] loss: 0.138 acc: 96.738\n","Train: [16,  1000] loss: 0.142 acc: 96.700\n","Train: [16,  1020] loss: 0.119 acc: 96.679\n","Train: [16,  1040] loss: 0.131 acc: 96.635\n","Train: [16,  1060] loss: 0.147 acc: 96.604\n","Train: [16,  1080] loss: 0.151 acc: 96.571\n","Train: [16,  1100] loss: 0.106 acc: 96.571\n","Train: [16,  1120] loss: 0.091 acc: 96.579\n","Train: [16,  1140] loss: 0.089 acc: 96.590\n","Train: [16,  1160] loss: 0.115 acc: 96.571\n","Train: [16,  1180] loss: 0.127 acc: 96.541\n","Train: [16,  1200] loss: 0.077 acc: 96.560\n","Train: [16,  1220] loss: 0.138 acc: 96.537\n","Train: [16,  1240] loss: 0.156 acc: 96.502\n","Train: [16,  1260] loss: 0.085 acc: 96.513\n","Train: [16,  1280] loss: 0.081 acc: 96.531\n","Train: [16,  1300] loss: 0.136 acc: 96.524\n","Train: [16,  1320] loss: 0.121 acc: 96.510\n","Train: [16,  1340] loss: 0.148 acc: 96.483\n","Train: [16,  1360] loss: 0.179 acc: 96.461\n","Train: [16,  1380] loss: 0.164 acc: 96.433\n","Train: [16,  1400] loss: 0.139 acc: 96.408\n","Train: [16,  1420] loss: 0.162 acc: 96.384\n","Train: [16,  1440] loss: 0.130 acc: 96.369\n","Train: [16,  1460] loss: 0.160 acc: 96.355\n","Train: [16,  1480] loss: 0.192 acc: 96.324\n","Train: [16,  1500] loss: 0.154 acc: 96.292\n","Train: [16,  1520] loss: 0.138 acc: 96.277\n","Train: [16,  1540] loss: 0.117 acc: 96.264\n","Train: [16,  1560] loss: 0.144 acc: 96.254\n","Test Accuracy: 75.270 %\n","Train: [17,    20] loss: 0.066 acc: 97.500\n","Train: [17,    40] loss: 0.070 acc: 97.656\n","Train: [17,    60] loss: 0.060 acc: 97.917\n","Train: [17,    80] loss: 0.074 acc: 97.812\n","Train: [17,   100] loss: 0.060 acc: 97.875\n","Train: [17,   120] loss: 0.068 acc: 97.839\n","Train: [17,   140] loss: 0.066 acc: 97.790\n","Train: [17,   160] loss: 0.054 acc: 97.930\n","Train: [17,   180] loss: 0.032 acc: 98.038\n","Train: [17,   200] loss: 0.063 acc: 98.000\n","Train: [17,   220] loss: 0.049 acc: 98.011\n","Train: [17,   240] loss: 0.064 acc: 97.943\n","Train: [17,   260] loss: 0.070 acc: 97.909\n","Train: [17,   280] loss: 0.060 acc: 97.902\n","Train: [17,   300] loss: 0.065 acc: 97.896\n","Train: [17,   320] loss: 0.064 acc: 97.920\n","Train: [17,   340] loss: 0.059 acc: 97.904\n","Train: [17,   360] loss: 0.051 acc: 97.925\n","Train: [17,   380] loss: 0.067 acc: 97.895\n","Train: [17,   400] loss: 0.102 acc: 97.805\n","Train: [17,   420] loss: 0.098 acc: 97.753\n","Train: [17,   440] loss: 0.130 acc: 97.628\n","Train: [17,   460] loss: 0.105 acc: 97.568\n","Train: [17,   480] loss: 0.112 acc: 97.526\n","Train: [17,   500] loss: 0.102 acc: 97.487\n","Train: [17,   520] loss: 0.081 acc: 97.494\n","Train: [17,   540] loss: 0.085 acc: 97.488\n","Train: [17,   560] loss: 0.073 acc: 97.483\n","Train: [17,   580] loss: 0.070 acc: 97.505\n","Train: [17,   600] loss: 0.065 acc: 97.510\n","Train: [17,   620] loss: 0.095 acc: 97.505\n","Train: [17,   640] loss: 0.058 acc: 97.505\n","Train: [17,   660] loss: 0.101 acc: 97.462\n","Train: [17,   680] loss: 0.113 acc: 97.394\n","Train: [17,   700] loss: 0.184 acc: 97.286\n","Train: [17,   720] loss: 0.106 acc: 97.253\n","Train: [17,   740] loss: 0.105 acc: 97.234\n","Train: [17,   760] loss: 0.160 acc: 97.163\n","Train: [17,   780] loss: 0.103 acc: 97.147\n","Train: [17,   800] loss: 0.114 acc: 97.125\n","Train: [17,   820] loss: 0.073 acc: 97.130\n","Train: [17,   840] loss: 0.093 acc: 97.121\n","Train: [17,   860] loss: 0.081 acc: 97.118\n","Train: [17,   880] loss: 0.095 acc: 97.120\n","Train: [17,   900] loss: 0.117 acc: 97.087\n","Train: [17,   920] loss: 0.092 acc: 97.079\n","Train: [17,   940] loss: 0.099 acc: 97.074\n","Train: [17,   960] loss: 0.121 acc: 97.038\n","Train: [17,   980] loss: 0.090 acc: 97.041\n","Train: [17,  1000] loss: 0.132 acc: 97.009\n","Train: [17,  1020] loss: 0.113 acc: 96.982\n","Train: [17,  1040] loss: 0.093 acc: 96.968\n","Train: [17,  1060] loss: 0.077 acc: 96.978\n","Train: [17,  1080] loss: 0.069 acc: 96.994\n","Train: [17,  1100] loss: 0.129 acc: 96.966\n","Train: [17,  1120] loss: 0.132 acc: 96.936\n","Train: [17,  1140] loss: 0.108 acc: 96.933\n","Train: [17,  1160] loss: 0.124 acc: 96.910\n","Train: [17,  1180] loss: 0.085 acc: 96.923\n","Train: [17,  1200] loss: 0.111 acc: 96.909\n","Train: [17,  1220] loss: 0.058 acc: 96.926\n","Train: [17,  1240] loss: 0.085 acc: 96.925\n","Train: [17,  1260] loss: 0.069 acc: 96.939\n","Train: [17,  1280] loss: 0.082 acc: 96.943\n","Train: [17,  1300] loss: 0.103 acc: 96.930\n","Train: [17,  1320] loss: 0.090 acc: 96.922\n","Train: [17,  1340] loss: 0.120 acc: 96.915\n","Train: [17,  1360] loss: 0.085 acc: 96.916\n","Train: [17,  1380] loss: 0.074 acc: 96.920\n","Train: [17,  1400] loss: 0.096 acc: 96.911\n","Train: [17,  1420] loss: 0.081 acc: 96.912\n","Train: [17,  1440] loss: 0.090 acc: 96.929\n","Train: [17,  1460] loss: 0.064 acc: 96.939\n","Train: [17,  1480] loss: 0.104 acc: 96.938\n","Train: [17,  1500] loss: 0.099 acc: 96.929\n","Train: [17,  1520] loss: 0.099 acc: 96.931\n","Train: [17,  1540] loss: 0.137 acc: 96.924\n","Train: [17,  1560] loss: 0.132 acc: 96.909\n","Test Accuracy: 74.870 %\n","Train: [18,    20] loss: 0.099 acc: 96.562\n","Train: [18,    40] loss: 0.090 acc: 96.484\n","Train: [18,    60] loss: 0.122 acc: 96.354\n","Train: [18,    80] loss: 0.093 acc: 96.523\n","Train: [18,   100] loss: 0.064 acc: 97.000\n","Train: [18,   120] loss: 0.071 acc: 97.005\n","Train: [18,   140] loss: 0.057 acc: 97.121\n","Train: [18,   160] loss: 0.066 acc: 97.188\n","Train: [18,   180] loss: 0.062 acc: 97.240\n","Train: [18,   200] loss: 0.051 acc: 97.266\n","Train: [18,   220] loss: 0.050 acc: 97.358\n","Train: [18,   240] loss: 0.045 acc: 97.461\n","Train: [18,   260] loss: 0.047 acc: 97.548\n","Train: [18,   280] loss: 0.058 acc: 97.567\n","Train: [18,   300] loss: 0.063 acc: 97.542\n","Train: [18,   320] loss: 0.082 acc: 97.539\n","Train: [18,   340] loss: 0.092 acc: 97.482\n","Train: [18,   360] loss: 0.088 acc: 97.448\n","Train: [18,   380] loss: 0.096 acc: 97.393\n","Train: [18,   400] loss: 0.072 acc: 97.398\n","Train: [18,   420] loss: 0.048 acc: 97.440\n","Train: [18,   440] loss: 0.062 acc: 97.472\n","Train: [18,   460] loss: 0.053 acc: 97.520\n","Train: [18,   480] loss: 0.062 acc: 97.526\n","Train: [18,   500] loss: 0.069 acc: 97.531\n","Train: [18,   520] loss: 0.050 acc: 97.548\n","Train: [18,   540] loss: 0.032 acc: 97.616\n","Train: [18,   560] loss: 0.084 acc: 97.628\n","Train: [18,   580] loss: 0.061 acc: 97.635\n","Train: [18,   600] loss: 0.051 acc: 97.641\n","Train: [18,   620] loss: 0.041 acc: 97.676\n","Train: [18,   640] loss: 0.054 acc: 97.671\n","Train: [18,   660] loss: 0.084 acc: 97.642\n","Train: [18,   680] loss: 0.070 acc: 97.647\n","Train: [18,   700] loss: 0.066 acc: 97.665\n","Train: [18,   720] loss: 0.097 acc: 97.635\n","Train: [18,   740] loss: 0.064 acc: 97.635\n","Train: [18,   760] loss: 0.066 acc: 97.640\n","Train: [18,   780] loss: 0.086 acc: 97.624\n","Train: [18,   800] loss: 0.085 acc: 97.586\n","Train: [18,   820] loss: 0.108 acc: 97.542\n","Train: [18,   840] loss: 0.117 acc: 97.507\n","Train: [18,   860] loss: 0.108 acc: 97.496\n","Train: [18,   880] loss: 0.102 acc: 97.472\n","Train: [18,   900] loss: 0.102 acc: 97.462\n","Train: [18,   920] loss: 0.114 acc: 97.422\n","Train: [18,   940] loss: 0.065 acc: 97.427\n","Train: [18,   960] loss: 0.068 acc: 97.428\n","Train: [18,   980] loss: 0.077 acc: 97.436\n","Train: [18,  1000] loss: 0.050 acc: 97.453\n","Train: [18,  1020] loss: 0.089 acc: 97.448\n","Train: [18,  1040] loss: 0.077 acc: 97.455\n","Train: [18,  1060] loss: 0.050 acc: 97.465\n","Train: [18,  1080] loss: 0.111 acc: 97.433\n","Train: [18,  1100] loss: 0.069 acc: 97.438\n","Train: [18,  1120] loss: 0.099 acc: 97.425\n","Train: [18,  1140] loss: 0.092 acc: 97.404\n","Train: [18,  1160] loss: 0.072 acc: 97.400\n","Train: [18,  1180] loss: 0.095 acc: 97.391\n","Train: [18,  1200] loss: 0.089 acc: 97.388\n","Train: [18,  1220] loss: 0.087 acc: 97.374\n","Train: [18,  1240] loss: 0.078 acc: 97.374\n","Train: [18,  1260] loss: 0.074 acc: 97.378\n","Train: [18,  1280] loss: 0.132 acc: 97.366\n","Train: [18,  1300] loss: 0.074 acc: 97.375\n","Train: [18,  1320] loss: 0.112 acc: 97.348\n","Train: [18,  1340] loss: 0.111 acc: 97.339\n","Train: [18,  1360] loss: 0.067 acc: 97.337\n","Train: [18,  1380] loss: 0.084 acc: 97.323\n","Train: [18,  1400] loss: 0.102 acc: 97.301\n","Train: [18,  1420] loss: 0.088 acc: 97.300\n","Train: [18,  1440] loss: 0.088 acc: 97.292\n","Train: [18,  1460] loss: 0.071 acc: 97.284\n","Train: [18,  1480] loss: 0.078 acc: 97.280\n","Train: [18,  1500] loss: 0.056 acc: 97.292\n","Train: [18,  1520] loss: 0.071 acc: 97.284\n","Train: [18,  1540] loss: 0.055 acc: 97.291\n","Train: [18,  1560] loss: 0.098 acc: 97.284\n","Test Accuracy: 74.590 %\n","Train: [19,    20] loss: 0.073 acc: 97.031\n","Train: [19,    40] loss: 0.055 acc: 97.422\n","Train: [19,    60] loss: 0.030 acc: 98.021\n","Train: [19,    80] loss: 0.046 acc: 98.086\n","Train: [19,   100] loss: 0.072 acc: 98.000\n","Train: [19,   120] loss: 0.071 acc: 97.917\n","Train: [19,   140] loss: 0.028 acc: 98.080\n","Train: [19,   160] loss: 0.029 acc: 98.184\n","Train: [19,   180] loss: 0.037 acc: 98.247\n","Train: [19,   200] loss: 0.053 acc: 98.250\n","Train: [19,   220] loss: 0.053 acc: 98.253\n","Train: [19,   240] loss: 0.048 acc: 98.255\n","Train: [19,   260] loss: 0.056 acc: 98.245\n","Train: [19,   280] loss: 0.058 acc: 98.237\n","Train: [19,   300] loss: 0.074 acc: 98.208\n","Train: [19,   320] loss: 0.046 acc: 98.232\n","Train: [19,   340] loss: 0.078 acc: 98.180\n","Train: [19,   360] loss: 0.064 acc: 98.116\n","Train: [19,   380] loss: 0.042 acc: 98.133\n","Train: [19,   400] loss: 0.057 acc: 98.133\n","Train: [19,   420] loss: 0.099 acc: 98.036\n","Train: [19,   440] loss: 0.096 acc: 97.947\n","Train: [19,   460] loss: 0.121 acc: 97.853\n","Train: [19,   480] loss: 0.072 acc: 97.826\n","Train: [19,   500] loss: 0.052 acc: 97.862\n","Train: [19,   520] loss: 0.071 acc: 97.855\n","Train: [19,   540] loss: 0.048 acc: 97.894\n","Train: [19,   560] loss: 0.055 acc: 97.891\n","Train: [19,   580] loss: 0.060 acc: 97.888\n","Train: [19,   600] loss: 0.060 acc: 97.901\n","Train: [19,   620] loss: 0.043 acc: 97.918\n","Train: [19,   640] loss: 0.059 acc: 97.925\n","Train: [19,   660] loss: 0.035 acc: 97.950\n","Train: [19,   680] loss: 0.043 acc: 97.964\n","Train: [19,   700] loss: 0.068 acc: 97.951\n","Train: [19,   720] loss: 0.038 acc: 97.960\n","Train: [19,   740] loss: 0.042 acc: 97.973\n","Train: [19,   760] loss: 0.038 acc: 97.989\n","Train: [19,   780] loss: 0.057 acc: 98.009\n","Train: [19,   800] loss: 0.056 acc: 97.992\n","Train: [19,   820] loss: 0.060 acc: 98.007\n","Train: [19,   840] loss: 0.056 acc: 98.010\n","Train: [19,   860] loss: 0.039 acc: 98.034\n","Train: [19,   880] loss: 0.102 acc: 98.004\n","Train: [19,   900] loss: 0.052 acc: 98.003\n","Train: [19,   920] loss: 0.067 acc: 97.996\n","Train: [19,   940] loss: 0.080 acc: 97.985\n","Train: [19,   960] loss: 0.036 acc: 97.992\n","Train: [19,   980] loss: 0.055 acc: 97.985\n","Train: [19,  1000] loss: 0.062 acc: 97.972\n","Train: [19,  1020] loss: 0.077 acc: 97.953\n","Train: [19,  1040] loss: 0.106 acc: 97.915\n","Train: [19,  1060] loss: 0.077 acc: 97.907\n","Train: [19,  1080] loss: 0.076 acc: 97.894\n","Train: [19,  1100] loss: 0.051 acc: 97.889\n","Train: [19,  1120] loss: 0.065 acc: 97.885\n","Train: [19,  1140] loss: 0.087 acc: 97.887\n","Train: [19,  1160] loss: 0.071 acc: 97.874\n","Train: [19,  1180] loss: 0.063 acc: 97.863\n","Train: [19,  1200] loss: 0.060 acc: 97.849\n","Train: [19,  1220] loss: 0.079 acc: 97.833\n","Train: [19,  1240] loss: 0.086 acc: 97.825\n","Train: [19,  1260] loss: 0.108 acc: 97.812\n","Train: [19,  1280] loss: 0.097 acc: 97.795\n","Train: [19,  1300] loss: 0.093 acc: 97.781\n","Train: [19,  1320] loss: 0.106 acc: 97.772\n","Train: [19,  1340] loss: 0.069 acc: 97.764\n","Train: [19,  1360] loss: 0.054 acc: 97.769\n","Train: [19,  1380] loss: 0.065 acc: 97.776\n","Train: [19,  1400] loss: 0.071 acc: 97.766\n","Train: [19,  1420] loss: 0.055 acc: 97.757\n","Train: [19,  1440] loss: 0.098 acc: 97.730\n","Train: [19,  1460] loss: 0.082 acc: 97.723\n","Train: [19,  1480] loss: 0.103 acc: 97.715\n","Train: [19,  1500] loss: 0.088 acc: 97.704\n","Train: [19,  1520] loss: 0.093 acc: 97.691\n","Train: [19,  1540] loss: 0.111 acc: 97.670\n","Train: [19,  1560] loss: 0.095 acc: 97.654\n","Test Accuracy: 74.320 %\n","Train: [20,    20] loss: 0.051 acc: 98.594\n","Train: [20,    40] loss: 0.051 acc: 98.047\n","Train: [20,    60] loss: 0.042 acc: 98.125\n","Train: [20,    80] loss: 0.059 acc: 98.047\n","Train: [20,   100] loss: 0.063 acc: 98.031\n","Train: [20,   120] loss: 0.036 acc: 98.203\n","Train: [20,   140] loss: 0.046 acc: 98.281\n","Train: [20,   160] loss: 0.060 acc: 98.242\n","Train: [20,   180] loss: 0.034 acc: 98.333\n","Train: [20,   200] loss: 0.052 acc: 98.297\n","Train: [20,   220] loss: 0.039 acc: 98.352\n","Train: [20,   240] loss: 0.043 acc: 98.372\n","Train: [20,   260] loss: 0.060 acc: 98.353\n","Train: [20,   280] loss: 0.062 acc: 98.270\n","Train: [20,   300] loss: 0.041 acc: 98.292\n","Train: [20,   320] loss: 0.082 acc: 98.184\n","Train: [20,   340] loss: 0.085 acc: 98.107\n","Train: [20,   360] loss: 0.063 acc: 98.116\n","Train: [20,   380] loss: 0.058 acc: 98.076\n","Train: [20,   400] loss: 0.061 acc: 98.078\n","Train: [20,   420] loss: 0.031 acc: 98.118\n","Train: [20,   440] loss: 0.044 acc: 98.111\n","Train: [20,   460] loss: 0.049 acc: 98.105\n","Train: [20,   480] loss: 0.073 acc: 98.099\n","Train: [20,   500] loss: 0.080 acc: 98.075\n","Train: [20,   520] loss: 0.038 acc: 98.089\n","Train: [20,   540] loss: 0.069 acc: 98.079\n","Train: [20,   560] loss: 0.096 acc: 98.025\n","Train: [20,   580] loss: 0.101 acc: 97.942\n","Train: [20,   600] loss: 0.046 acc: 97.943\n","Train: [20,   620] loss: 0.044 acc: 97.959\n","Train: [20,   640] loss: 0.061 acc: 97.935\n","Train: [20,   660] loss: 0.065 acc: 97.926\n","Train: [20,   680] loss: 0.072 acc: 97.909\n","Train: [20,   700] loss: 0.076 acc: 97.893\n","Train: [20,   720] loss: 0.128 acc: 97.856\n","Train: [20,   740] loss: 0.085 acc: 97.829\n","Train: [20,   760] loss: 0.081 acc: 97.804\n","Train: [20,   780] loss: 0.077 acc: 97.768\n","Train: [20,   800] loss: 0.130 acc: 97.715\n","Train: [20,   820] loss: 0.047 acc: 97.729\n","Train: [20,   840] loss: 0.039 acc: 97.749\n","Train: [20,   860] loss: 0.050 acc: 97.762\n","Train: [20,   880] loss: 0.048 acc: 97.773\n","Train: [20,   900] loss: 0.077 acc: 97.750\n","Train: [20,   920] loss: 0.073 acc: 97.745\n","Train: [20,   940] loss: 0.095 acc: 97.719\n","Train: [20,   960] loss: 0.085 acc: 97.708\n","Train: [20,   980] loss: 0.082 acc: 97.701\n","Train: [20,  1000] loss: 0.036 acc: 97.716\n","Train: [20,  1020] loss: 0.070 acc: 97.721\n","Train: [20,  1040] loss: 0.055 acc: 97.725\n","Train: [20,  1060] loss: 0.071 acc: 97.724\n","Train: [20,  1080] loss: 0.060 acc: 97.726\n","Train: [20,  1100] loss: 0.066 acc: 97.733\n","Train: [20,  1120] loss: 0.067 acc: 97.734\n","Train: [20,  1140] loss: 0.076 acc: 97.728\n","Train: [20,  1160] loss: 0.082 acc: 97.718\n","Train: [20,  1180] loss: 0.077 acc: 97.717\n","Train: [20,  1200] loss: 0.056 acc: 97.719\n","Train: [20,  1220] loss: 0.099 acc: 97.692\n","Train: [20,  1240] loss: 0.107 acc: 97.669\n","Train: [20,  1260] loss: 0.103 acc: 97.651\n","Train: [20,  1280] loss: 0.050 acc: 97.654\n","Train: [20,  1300] loss: 0.047 acc: 97.661\n","Train: [20,  1320] loss: 0.055 acc: 97.673\n","Train: [20,  1340] loss: 0.068 acc: 97.675\n","Train: [20,  1360] loss: 0.059 acc: 97.679\n","Train: [20,  1380] loss: 0.065 acc: 97.672\n","Train: [20,  1400] loss: 0.094 acc: 97.645\n","Train: [20,  1420] loss: 0.097 acc: 97.636\n","Train: [20,  1440] loss: 0.091 acc: 97.626\n","Train: [20,  1460] loss: 0.115 acc: 97.609\n","Train: [20,  1480] loss: 0.074 acc: 97.601\n","Train: [20,  1500] loss: 0.081 acc: 97.598\n","Train: [20,  1520] loss: 0.071 acc: 97.603\n","Train: [20,  1540] loss: 0.059 acc: 97.601\n","Train: [20,  1560] loss: 0.092 acc: 97.586\n","Test Accuracy: 75.240 %\n","Train: [21,    20] loss: 0.027 acc: 99.219\n","Train: [21,    40] loss: 0.043 acc: 99.141\n","Train: [21,    60] loss: 0.033 acc: 99.010\n","Train: [21,    80] loss: 0.044 acc: 98.789\n","Train: [21,   100] loss: 0.048 acc: 98.688\n","Train: [21,   120] loss: 0.059 acc: 98.516\n","Train: [21,   140] loss: 0.058 acc: 98.438\n","Train: [21,   160] loss: 0.044 acc: 98.359\n","Train: [21,   180] loss: 0.047 acc: 98.403\n","Train: [21,   200] loss: 0.023 acc: 98.484\n","Train: [21,   220] loss: 0.033 acc: 98.551\n","Train: [21,   240] loss: 0.039 acc: 98.568\n","Train: [21,   260] loss: 0.045 acc: 98.582\n","Train: [21,   280] loss: 0.043 acc: 98.560\n","Train: [21,   300] loss: 0.070 acc: 98.479\n","Train: [21,   320] loss: 0.093 acc: 98.379\n","Train: [21,   340] loss: 0.105 acc: 98.235\n","Train: [21,   360] loss: 0.113 acc: 98.125\n","Train: [21,   380] loss: 0.095 acc: 98.035\n","Train: [21,   400] loss: 0.065 acc: 98.000\n","Train: [21,   420] loss: 0.061 acc: 97.954\n","Train: [21,   440] loss: 0.048 acc: 97.962\n","Train: [21,   460] loss: 0.039 acc: 98.003\n","Train: [21,   480] loss: 0.043 acc: 98.034\n","Train: [21,   500] loss: 0.053 acc: 98.056\n","Train: [21,   520] loss: 0.034 acc: 98.083\n","Train: [21,   540] loss: 0.036 acc: 98.119\n","Train: [21,   560] loss: 0.043 acc: 98.142\n","Train: [21,   580] loss: 0.048 acc: 98.163\n","Train: [21,   600] loss: 0.063 acc: 98.141\n","Train: [21,   620] loss: 0.075 acc: 98.125\n","Train: [21,   640] loss: 0.097 acc: 98.091\n","Train: [21,   660] loss: 0.061 acc: 98.078\n","Train: [21,   680] loss: 0.049 acc: 98.088\n","Train: [21,   700] loss: 0.063 acc: 98.089\n","Train: [21,   720] loss: 0.069 acc: 98.077\n","Train: [21,   740] loss: 0.069 acc: 98.062\n","Train: [21,   760] loss: 0.042 acc: 98.076\n","Train: [21,   780] loss: 0.054 acc: 98.069\n","Train: [21,   800] loss: 0.074 acc: 98.062\n","Train: [21,   820] loss: 0.040 acc: 98.079\n","Train: [21,   840] loss: 0.052 acc: 98.092\n","Train: [21,   860] loss: 0.026 acc: 98.114\n","Train: [21,   880] loss: 0.041 acc: 98.129\n","Train: [21,   900] loss: 0.038 acc: 98.142\n","Train: [21,   920] loss: 0.047 acc: 98.156\n","Train: [21,   940] loss: 0.062 acc: 98.148\n","Train: [21,   960] loss: 0.092 acc: 98.125\n","Train: [21,   980] loss: 0.037 acc: 98.131\n","Train: [21,  1000] loss: 0.085 acc: 98.109\n","Train: [21,  1020] loss: 0.056 acc: 98.107\n","Train: [21,  1040] loss: 0.053 acc: 98.110\n","Train: [21,  1060] loss: 0.066 acc: 98.107\n","Train: [21,  1080] loss: 0.062 acc: 98.087\n","Train: [21,  1100] loss: 0.044 acc: 98.085\n","Train: [21,  1120] loss: 0.055 acc: 98.092\n","Train: [21,  1140] loss: 0.076 acc: 98.084\n","Train: [21,  1160] loss: 0.083 acc: 98.074\n","Train: [21,  1180] loss: 0.098 acc: 98.056\n","Train: [21,  1200] loss: 0.073 acc: 98.049\n","Train: [21,  1220] loss: 0.061 acc: 98.033\n","Train: [21,  1240] loss: 0.056 acc: 98.029\n","Train: [21,  1260] loss: 0.057 acc: 98.033\n","Train: [21,  1280] loss: 0.085 acc: 98.018\n","Train: [21,  1300] loss: 0.065 acc: 98.002\n","Train: [21,  1320] loss: 0.059 acc: 97.995\n","Train: [21,  1340] loss: 0.084 acc: 97.969\n","Train: [21,  1360] loss: 0.076 acc: 97.957\n","Train: [21,  1380] loss: 0.093 acc: 97.942\n","Train: [21,  1400] loss: 0.061 acc: 97.929\n","Train: [21,  1420] loss: 0.041 acc: 97.934\n","Train: [21,  1440] loss: 0.094 acc: 97.914\n","Train: [21,  1460] loss: 0.086 acc: 97.898\n","Train: [21,  1480] loss: 0.098 acc: 97.867\n","Train: [21,  1500] loss: 0.071 acc: 97.865\n","Train: [21,  1520] loss: 0.062 acc: 97.862\n","Train: [21,  1540] loss: 0.056 acc: 97.865\n","Train: [21,  1560] loss: 0.079 acc: 97.851\n","Test Accuracy: 75.780 %\n","Train: [22,    20] loss: 0.059 acc: 97.812\n","Train: [22,    40] loss: 0.068 acc: 97.656\n","Train: [22,    60] loss: 0.048 acc: 97.969\n","Train: [22,    80] loss: 0.045 acc: 98.008\n","Train: [22,   100] loss: 0.046 acc: 98.031\n","Train: [22,   120] loss: 0.039 acc: 98.099\n","Train: [22,   140] loss: 0.035 acc: 98.259\n","Train: [22,   160] loss: 0.037 acc: 98.379\n","Train: [22,   180] loss: 0.035 acc: 98.420\n","Train: [22,   200] loss: 0.049 acc: 98.375\n","Train: [22,   220] loss: 0.028 acc: 98.452\n","Train: [22,   240] loss: 0.034 acc: 98.490\n","Train: [22,   260] loss: 0.034 acc: 98.498\n","Train: [22,   280] loss: 0.037 acc: 98.527\n","Train: [22,   300] loss: 0.046 acc: 98.521\n","Train: [22,   320] loss: 0.025 acc: 98.525\n","Train: [22,   340] loss: 0.036 acc: 98.529\n","Train: [22,   360] loss: 0.027 acc: 98.550\n","Train: [22,   380] loss: 0.037 acc: 98.577\n","Train: [22,   400] loss: 0.020 acc: 98.617\n","Train: [22,   420] loss: 0.026 acc: 98.638\n","Train: [22,   440] loss: 0.051 acc: 98.622\n","Train: [22,   460] loss: 0.033 acc: 98.655\n","Train: [22,   480] loss: 0.023 acc: 98.685\n","Train: [22,   500] loss: 0.035 acc: 98.675\n","Train: [22,   520] loss: 0.034 acc: 98.684\n","Train: [22,   540] loss: 0.041 acc: 98.675\n","Train: [22,   560] loss: 0.022 acc: 98.700\n","Train: [22,   580] loss: 0.028 acc: 98.712\n","Train: [22,   600] loss: 0.040 acc: 98.703\n","Train: [22,   620] loss: 0.060 acc: 98.684\n","Train: [22,   640] loss: 0.061 acc: 98.662\n","Train: [22,   660] loss: 0.061 acc: 98.641\n","Train: [22,   680] loss: 0.071 acc: 98.598\n","Train: [22,   700] loss: 0.034 acc: 98.607\n","Train: [22,   720] loss: 0.040 acc: 98.615\n","Train: [22,   740] loss: 0.035 acc: 98.628\n","Train: [22,   760] loss: 0.029 acc: 98.631\n","Train: [22,   780] loss: 0.040 acc: 98.634\n","Train: [22,   800] loss: 0.084 acc: 98.609\n","Train: [22,   820] loss: 0.068 acc: 98.575\n","Train: [22,   840] loss: 0.060 acc: 98.553\n","Train: [22,   860] loss: 0.077 acc: 98.525\n","Train: [22,   880] loss: 0.062 acc: 98.501\n","Train: [22,   900] loss: 0.059 acc: 98.497\n","Train: [22,   920] loss: 0.063 acc: 98.482\n","Train: [22,   940] loss: 0.106 acc: 98.431\n","Train: [22,   960] loss: 0.092 acc: 98.402\n","Train: [22,   980] loss: 0.072 acc: 98.383\n","Train: [22,  1000] loss: 0.059 acc: 98.362\n","Train: [22,  1020] loss: 0.058 acc: 98.352\n","Train: [22,  1040] loss: 0.058 acc: 98.338\n","Train: [22,  1060] loss: 0.079 acc: 98.308\n","Train: [22,  1080] loss: 0.056 acc: 98.302\n","Train: [22,  1100] loss: 0.042 acc: 98.301\n","Train: [22,  1120] loss: 0.070 acc: 98.290\n","Train: [22,  1140] loss: 0.061 acc: 98.289\n","Train: [22,  1160] loss: 0.084 acc: 98.270\n","Train: [22,  1180] loss: 0.078 acc: 98.249\n","Train: [22,  1200] loss: 0.098 acc: 98.224\n","Train: [22,  1220] loss: 0.124 acc: 98.207\n","Train: [22,  1240] loss: 0.068 acc: 98.201\n","Train: [22,  1260] loss: 0.069 acc: 98.197\n","Train: [22,  1280] loss: 0.072 acc: 98.196\n","Train: [22,  1300] loss: 0.068 acc: 98.192\n","Train: [22,  1320] loss: 0.057 acc: 98.196\n","Train: [22,  1340] loss: 0.093 acc: 98.179\n","Train: [22,  1360] loss: 0.071 acc: 98.171\n","Train: [22,  1380] loss: 0.087 acc: 98.145\n","Train: [22,  1400] loss: 0.078 acc: 98.141\n","Train: [22,  1420] loss: 0.066 acc: 98.136\n","Train: [22,  1440] loss: 0.068 acc: 98.121\n","Train: [22,  1460] loss: 0.057 acc: 98.116\n","Train: [22,  1480] loss: 0.071 acc: 98.106\n","Train: [22,  1500] loss: 0.098 acc: 98.092\n","Train: [22,  1520] loss: 0.102 acc: 98.061\n","Train: [22,  1540] loss: 0.132 acc: 98.036\n","Train: [22,  1560] loss: 0.113 acc: 98.015\n","Test Accuracy: 75.140 %\n","Train: [23,    20] loss: 0.084 acc: 97.031\n","Train: [23,    40] loss: 0.070 acc: 97.031\n","Train: [23,    60] loss: 0.089 acc: 96.823\n","Train: [23,    80] loss: 0.077 acc: 96.914\n","Train: [23,   100] loss: 0.053 acc: 97.094\n","Train: [23,   120] loss: 0.067 acc: 97.292\n","Train: [23,   140] loss: 0.047 acc: 97.388\n","Train: [23,   160] loss: 0.105 acc: 97.266\n","Train: [23,   180] loss: 0.059 acc: 97.292\n","Train: [23,   200] loss: 0.054 acc: 97.375\n","Train: [23,   220] loss: 0.051 acc: 97.443\n","Train: [23,   240] loss: 0.058 acc: 97.474\n","Train: [23,   260] loss: 0.061 acc: 97.476\n","Train: [23,   280] loss: 0.058 acc: 97.511\n","Train: [23,   300] loss: 0.040 acc: 97.594\n","Train: [23,   320] loss: 0.052 acc: 97.627\n","Train: [23,   340] loss: 0.076 acc: 97.619\n","Train: [23,   360] loss: 0.064 acc: 97.639\n","Train: [23,   380] loss: 0.034 acc: 97.706\n","Train: [23,   400] loss: 0.064 acc: 97.703\n","Train: [23,   420] loss: 0.066 acc: 97.716\n","Train: [23,   440] loss: 0.072 acc: 97.699\n","Train: [23,   460] loss: 0.048 acc: 97.711\n","Train: [23,   480] loss: 0.048 acc: 97.715\n","Train: [23,   500] loss: 0.055 acc: 97.706\n","Train: [23,   520] loss: 0.051 acc: 97.734\n","Train: [23,   540] loss: 0.027 acc: 97.789\n","Train: [23,   560] loss: 0.032 acc: 97.840\n","Train: [23,   580] loss: 0.028 acc: 97.899\n","Train: [23,   600] loss: 0.062 acc: 97.901\n","Train: [23,   620] loss: 0.047 acc: 97.903\n","Train: [23,   640] loss: 0.049 acc: 97.891\n","Train: [23,   660] loss: 0.045 acc: 97.898\n","Train: [23,   680] loss: 0.087 acc: 97.881\n","Train: [23,   700] loss: 0.074 acc: 97.875\n","Train: [23,   720] loss: 0.072 acc: 97.878\n","Train: [23,   740] loss: 0.057 acc: 97.889\n","Train: [23,   760] loss: 0.050 acc: 97.895\n","Train: [23,   780] loss: 0.073 acc: 97.893\n","Train: [23,   800] loss: 0.039 acc: 97.918\n","Train: [23,   820] loss: 0.046 acc: 97.931\n","Train: [23,   840] loss: 0.055 acc: 97.943\n","Train: [23,   860] loss: 0.045 acc: 97.954\n","Train: [23,   880] loss: 0.041 acc: 97.962\n","Train: [23,   900] loss: 0.033 acc: 97.990\n","Train: [23,   920] loss: 0.037 acc: 98.016\n","Train: [23,   940] loss: 0.036 acc: 98.025\n","Train: [23,   960] loss: 0.064 acc: 98.021\n","Train: [23,   980] loss: 0.080 acc: 98.001\n","Train: [23,  1000] loss: 0.054 acc: 97.994\n","Train: [23,  1020] loss: 0.057 acc: 97.993\n","Train: [23,  1040] loss: 0.038 acc: 98.008\n","Train: [23,  1060] loss: 0.047 acc: 98.013\n","Train: [23,  1080] loss: 0.042 acc: 98.021\n","Train: [23,  1100] loss: 0.046 acc: 98.037\n","Train: [23,  1120] loss: 0.054 acc: 98.039\n","Train: [23,  1140] loss: 0.043 acc: 98.051\n","Train: [23,  1160] loss: 0.050 acc: 98.063\n","Train: [23,  1180] loss: 0.050 acc: 98.064\n","Train: [23,  1200] loss: 0.065 acc: 98.057\n","Train: [23,  1220] loss: 0.063 acc: 98.046\n","Train: [23,  1240] loss: 0.049 acc: 98.054\n","Train: [23,  1260] loss: 0.055 acc: 98.053\n","Train: [23,  1280] loss: 0.060 acc: 98.040\n","Train: [23,  1300] loss: 0.062 acc: 98.048\n","Train: [23,  1320] loss: 0.051 acc: 98.052\n","Train: [23,  1340] loss: 0.046 acc: 98.060\n","Train: [23,  1360] loss: 0.052 acc: 98.065\n","Train: [23,  1380] loss: 0.065 acc: 98.062\n","Train: [23,  1400] loss: 0.094 acc: 98.045\n","Train: [23,  1420] loss: 0.081 acc: 98.033\n","Train: [23,  1440] loss: 0.045 acc: 98.036\n","Train: [23,  1460] loss: 0.061 acc: 98.039\n","Train: [23,  1480] loss: 0.102 acc: 98.019\n","Train: [23,  1500] loss: 0.057 acc: 98.019\n","Train: [23,  1520] loss: 0.052 acc: 98.016\n","Train: [23,  1540] loss: 0.045 acc: 98.024\n","Train: [23,  1560] loss: 0.104 acc: 98.005\n","Test Accuracy: 74.800 %\n","Train: [24,    20] loss: 0.073 acc: 98.125\n","Train: [24,    40] loss: 0.047 acc: 98.281\n","Train: [24,    60] loss: 0.030 acc: 98.594\n","Train: [24,    80] loss: 0.030 acc: 98.633\n","Train: [24,   100] loss: 0.035 acc: 98.594\n","Train: [24,   120] loss: 0.050 acc: 98.594\n","Train: [24,   140] loss: 0.028 acc: 98.638\n","Train: [24,   160] loss: 0.038 acc: 98.652\n","Train: [24,   180] loss: 0.038 acc: 98.628\n","Train: [24,   200] loss: 0.038 acc: 98.625\n","Train: [24,   220] loss: 0.020 acc: 98.679\n","Train: [24,   240] loss: 0.023 acc: 98.711\n","Train: [24,   260] loss: 0.030 acc: 98.726\n","Train: [24,   280] loss: 0.018 acc: 98.795\n","Train: [24,   300] loss: 0.030 acc: 98.823\n","Train: [24,   320] loss: 0.037 acc: 98.828\n","Train: [24,   340] loss: 0.032 acc: 98.851\n","Train: [24,   360] loss: 0.021 acc: 98.880\n","Train: [24,   380] loss: 0.024 acc: 98.882\n","Train: [24,   400] loss: 0.015 acc: 98.914\n","Train: [24,   420] loss: 0.017 acc: 98.936\n","Train: [24,   440] loss: 0.022 acc: 98.963\n","Train: [24,   460] loss: 0.043 acc: 98.954\n","Train: [24,   480] loss: 0.056 acc: 98.906\n","Train: [24,   500] loss: 0.023 acc: 98.919\n","Train: [24,   520] loss: 0.031 acc: 98.894\n","Train: [24,   540] loss: 0.028 acc: 98.877\n","Train: [24,   560] loss: 0.020 acc: 98.890\n","Train: [24,   580] loss: 0.015 acc: 98.906\n","Train: [24,   600] loss: 0.021 acc: 98.917\n","Train: [24,   620] loss: 0.042 acc: 98.916\n","Train: [24,   640] loss: 0.032 acc: 98.906\n","Train: [24,   660] loss: 0.038 acc: 98.897\n","Train: [24,   680] loss: 0.013 acc: 98.920\n","Train: [24,   700] loss: 0.061 acc: 98.888\n","Train: [24,   720] loss: 0.063 acc: 98.850\n","Train: [24,   740] loss: 0.037 acc: 98.847\n","Train: [24,   760] loss: 0.053 acc: 98.836\n","Train: [24,   780] loss: 0.052 acc: 98.826\n","Train: [24,   800] loss: 0.026 acc: 98.832\n","Train: [24,   820] loss: 0.026 acc: 98.838\n","Train: [24,   840] loss: 0.032 acc: 98.832\n","Train: [24,   860] loss: 0.057 acc: 98.808\n","Train: [24,   880] loss: 0.046 acc: 98.803\n","Train: [24,   900] loss: 0.057 acc: 98.785\n","Train: [24,   920] loss: 0.053 acc: 98.770\n","Train: [24,   940] loss: 0.036 acc: 98.767\n","Train: [24,   960] loss: 0.042 acc: 98.763\n","Train: [24,   980] loss: 0.056 acc: 98.753\n","Train: [24,  1000] loss: 0.041 acc: 98.747\n","Train: [24,  1020] loss: 0.053 acc: 98.738\n","Train: [24,  1040] loss: 0.035 acc: 98.738\n","Train: [24,  1060] loss: 0.046 acc: 98.735\n","Train: [24,  1080] loss: 0.055 acc: 98.730\n","Train: [24,  1100] loss: 0.038 acc: 98.722\n","Train: [24,  1120] loss: 0.054 acc: 98.711\n","Train: [24,  1140] loss: 0.039 acc: 98.703\n","Train: [24,  1160] loss: 0.045 acc: 98.702\n","Train: [24,  1180] loss: 0.048 acc: 98.692\n","Train: [24,  1200] loss: 0.062 acc: 98.677\n","Train: [24,  1220] loss: 0.053 acc: 98.663\n","Train: [24,  1240] loss: 0.042 acc: 98.657\n","Train: [24,  1260] loss: 0.043 acc: 98.646\n","Train: [24,  1280] loss: 0.045 acc: 98.650\n","Train: [24,  1300] loss: 0.065 acc: 98.637\n","Train: [24,  1320] loss: 0.051 acc: 98.636\n","Train: [24,  1340] loss: 0.039 acc: 98.636\n","Train: [24,  1360] loss: 0.080 acc: 98.612\n","Train: [24,  1380] loss: 0.044 acc: 98.607\n","Train: [24,  1400] loss: 0.048 acc: 98.605\n","Train: [24,  1420] loss: 0.047 acc: 98.603\n","Train: [24,  1440] loss: 0.059 acc: 98.589\n","Train: [24,  1460] loss: 0.070 acc: 98.583\n","Train: [24,  1480] loss: 0.048 acc: 98.583\n","Train: [24,  1500] loss: 0.035 acc: 98.583\n","Train: [24,  1520] loss: 0.067 acc: 98.567\n","Train: [24,  1540] loss: 0.059 acc: 98.565\n","Train: [24,  1560] loss: 0.059 acc: 98.564\n","Test Accuracy: 75.660 %\n","Train: [25,    20] loss: 0.061 acc: 97.500\n","Train: [25,    40] loss: 0.061 acc: 97.734\n","Train: [25,    60] loss: 0.050 acc: 97.969\n","Train: [25,    80] loss: 0.047 acc: 98.086\n","Train: [25,   100] loss: 0.041 acc: 98.125\n","Train: [25,   120] loss: 0.055 acc: 98.177\n","Train: [25,   140] loss: 0.025 acc: 98.326\n","Train: [25,   160] loss: 0.031 acc: 98.359\n","Train: [25,   180] loss: 0.027 acc: 98.403\n","Train: [25,   200] loss: 0.041 acc: 98.422\n","Train: [25,   220] loss: 0.030 acc: 98.466\n","Train: [25,   240] loss: 0.041 acc: 98.464\n","Train: [25,   260] loss: 0.055 acc: 98.425\n","Train: [25,   280] loss: 0.056 acc: 98.415\n","Train: [25,   300] loss: 0.043 acc: 98.385\n","Train: [25,   320] loss: 0.022 acc: 98.438\n","Train: [25,   340] loss: 0.020 acc: 98.493\n","Train: [25,   360] loss: 0.024 acc: 98.542\n","Train: [25,   380] loss: 0.025 acc: 98.553\n","Train: [25,   400] loss: 0.032 acc: 98.570\n","Train: [25,   420] loss: 0.040 acc: 98.564\n","Train: [25,   440] loss: 0.038 acc: 98.580\n","Train: [25,   460] loss: 0.040 acc: 98.580\n","Train: [25,   480] loss: 0.036 acc: 98.574\n","Train: [25,   500] loss: 0.051 acc: 98.556\n","Train: [25,   520] loss: 0.041 acc: 98.546\n","Train: [25,   540] loss: 0.067 acc: 98.547\n","Train: [25,   560] loss: 0.058 acc: 98.516\n","Train: [25,   580] loss: 0.054 acc: 98.513\n","Train: [25,   600] loss: 0.050 acc: 98.500\n","Train: [25,   620] loss: 0.061 acc: 98.468\n","Train: [25,   640] loss: 0.046 acc: 98.462\n","Train: [25,   660] loss: 0.034 acc: 98.480\n","Train: [25,   680] loss: 0.046 acc: 98.483\n","Train: [25,   700] loss: 0.033 acc: 98.496\n","Train: [25,   720] loss: 0.059 acc: 98.485\n","Train: [25,   740] loss: 0.056 acc: 98.476\n","Train: [25,   760] loss: 0.071 acc: 98.450\n","Train: [25,   780] loss: 0.058 acc: 98.433\n","Train: [25,   800] loss: 0.068 acc: 98.418\n","Train: [25,   820] loss: 0.045 acc: 98.407\n","Train: [25,   840] loss: 0.060 acc: 98.408\n","Train: [25,   860] loss: 0.069 acc: 98.387\n","Train: [25,   880] loss: 0.056 acc: 98.381\n","Train: [25,   900] loss: 0.051 acc: 98.372\n","Train: [25,   920] loss: 0.043 acc: 98.373\n","Train: [25,   940] loss: 0.046 acc: 98.361\n","Train: [25,   960] loss: 0.025 acc: 98.372\n","Train: [25,   980] loss: 0.058 acc: 98.374\n","Train: [25,  1000] loss: 0.032 acc: 98.391\n","Train: [25,  1020] loss: 0.047 acc: 98.382\n","Train: [25,  1040] loss: 0.047 acc: 98.377\n","Train: [25,  1060] loss: 0.057 acc: 98.376\n","Train: [25,  1080] loss: 0.151 acc: 98.325\n","Train: [25,  1100] loss: 0.089 acc: 98.284\n","Train: [25,  1120] loss: 0.108 acc: 98.245\n","Train: [25,  1140] loss: 0.104 acc: 98.213\n","Train: [25,  1160] loss: 0.066 acc: 98.211\n","Train: [25,  1180] loss: 0.042 acc: 98.210\n","Train: [25,  1200] loss: 0.056 acc: 98.201\n","Train: [25,  1220] loss: 0.054 acc: 98.197\n","Train: [25,  1240] loss: 0.030 acc: 98.206\n","Train: [25,  1260] loss: 0.053 acc: 98.202\n","Train: [25,  1280] loss: 0.039 acc: 98.215\n","Train: [25,  1300] loss: 0.047 acc: 98.214\n","Train: [25,  1320] loss: 0.067 acc: 98.198\n","Train: [25,  1340] loss: 0.070 acc: 98.193\n","Train: [25,  1360] loss: 0.106 acc: 98.173\n","Train: [25,  1380] loss: 0.134 acc: 98.143\n","Train: [25,  1400] loss: 0.072 acc: 98.145\n","Train: [25,  1420] loss: 0.075 acc: 98.132\n","Train: [25,  1440] loss: 0.066 acc: 98.123\n","Train: [25,  1460] loss: 0.105 acc: 98.104\n","Train: [25,  1480] loss: 0.093 acc: 98.085\n","Train: [25,  1500] loss: 0.092 acc: 98.077\n","Train: [25,  1520] loss: 0.081 acc: 98.063\n","Train: [25,  1540] loss: 0.042 acc: 98.072\n","Train: [25,  1560] loss: 0.073 acc: 98.059\n","Test Accuracy: 75.560 %\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Finished Training\n","Final Test Accuracy of the Best Model: 75.560 %\n"]}]}],"metadata":{"language_info":{"name":"python"},"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":0}